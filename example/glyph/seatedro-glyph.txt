Directory structure:
└── seatedro-glyph/
    ├── readme.md
    ├── bench.c.sh
    ├── bench.zig.sh
    ├── build.zig
    ├── build.zig.zon
    ├── LICENSE
    ├── src/
    │   ├── bitmap.zig
    │   ├── core.zig
    │   ├── image.zig
    │   ├── main.zig
    │   ├── mime.zig
    │   ├── term.zig
    │   ├── tests.zig
    │   └── video.zig
    ├── vendor/
    │   ├── av.zig
    │   ├── stb.c
    │   └── stb.zig
    └── .github/
        └── workflows/
            ├── bump.yml
            ├── release.yml
            └── test.yml

================================================
File: readme.md
================================================
# glyph - ascii from media

converts images/video to ascii art


## Dependencies

these dependencies are only for the `av` library to output videos. This will be opt-in in the future.

#### Linux:
```bash
sudo apt-get install libavutil-dev libavformat-dev libavcodec-dev libswscale-dev
```

#### MacOS:
```bash
brew install ffmpeg pkgconf
```

#### Windows:
```bash
choco install ffmpeg-shared
```

## Installing

#### Homebrew
```bash
brew install glyph
```

### build from source

`zig build -Doptimize=ReleaseFast`

the above command builds an executable found at `./zig-out/bin`

if you want to just directly run the executable, run:

`zig build run -Doptimize=ReleaseFast -- [options]`

see below for explanations for available options

## Usage

run the program with the following options (the default zig install directory is `./zig-out/bin`):
   ```
   /path/to/glyph [options]
   ```
1. options:
   - `-h, --help`: print the help message and exit
   - `-i, --input <file>`: specify the input media file path (local path/URL) (required)
   - `-o, --output <file>`: specify the output media file (txt/img/vid) (required)
   - `-c, --color`: use color ascii characters (optional)
   - `-n, --invert_color`: Inverts the color values (optional)
   - `-s, --scale <float>`: set the downscale or upscale factor (optional, default: 1)
   - `-e, --detect_edges`: enable edge detection (optional)
   - `    --sigma1 <float>`: set the sigma1 value for DoG filter (optional, default: 0.3)
   - `    --sigma2 <float>`: set the sigma2 value for DoG filter (optional, default: 1.0)
   - `    --dither floydstein`: enable dithering (currently only supports floydstein algorithm)
   - `-b, --brightness_boost <float>`: increase/decrease perceived brightness (optional, default: 1.0)
   advanced options:
   - `    --full_characters`: Uses all ascii characters in generated output.
   - `    --ascii_chars <string>`: Use what characters you want to use in the generated output. (default: " .:-=+*%@#")
   - `    --disable_sort`: Prevents sorting of the ascii_chars by size.
   - `    --block_size <u8>`: Set the size of the blocks. (default: 8)
   - `    --threshold_disabled`: Disables the threshold.
   - `    --codec <string>`: Set the encoder codec like "libx264" or "hevc_videotoolbox". (default: searches for encoders on your machine)
   - `    --keep_audio`: Preserves audio from input video.
   - `    --stretched`: Resizes media to fit terminal window
   - `-f, --frame_rate`: Target frame rate for video output (default: matches input fps)

>To render on the terminal directly, just omit the output option.

>To output to a text file, use the .txt extension when setting the output option

2. examples:

   ### Image

   basic usage:
   ```bash
   glyph -i input.jpg -o output.png
   ```

   text file output:
   ```bash
   glyph -i input.jpg -o output.txt
   ```

   using color:
   ```bash
   glyph -i input.png -o output.png -c
   ```

   with edge detection, color, and custom downscale:
   ```bash
   glyph -i input.jpeg -o output.png -s 4 -e -c
   ```

   with brightness boost and url input:
   ```bash
   # bonus (this is a sweet wallpaper)
   glyph -i "https://w.wallhaven.cc/full/p9/wallhaven-p9gr2p.jpg" -o output.png -e -c -b 1.5
   ```

   terminal output (just omit the output option):
   ```bash
   glyph -i "https://w.wallhaven.cc/full/p9/wallhaven-p9gr2p.jpg" -e -c -b 1.5
   ```

   ### Video

   with an input video (no urls allowed):
   ```bash
   glyph -i /path/to/input/video.mp4 -o ascii.mp4 --codec hevc_nvenc --keep_audio
   ```

   with an input video and rendering on the terminal (stretched to fit terminal):
   ```bash
   glyph -i /path/to/input/video.mp4 --stretched -c
   ```

   with input video and custom ffmpeg encoder options:
   ```bash
   glyph -i /path/to/input/video.mp4 -o ascii.mp4 -c --codec libx264 --keep_audio-- -preset fast -crf 20
   ```

   with input video and custom ffmpeg encoder options:
   ```bash
   glyph -i /path/to/input/video.mp4 -o ascii.mp4 -c --codec libx264 --keep_audio-- -preset fast -crf 20
   ```

3. the program will generate an ascii art version of your input media and save it as a new media file.

for images: output file needs to be a `.png` since i saw some weird issues with jpegs.

4. using the long arguments on windows may or may not work. please use the short arguments for now.



================================================
File: bench.c.sh
================================================
cd stb
zig cc -O3 -o main main.c -lm
./main green_vagabond.jpg



================================================
File: bench.zig.sh
================================================
# zig build run -Drelease -- -i images/skull.png -o ascii.png -e -c -b 15.0
zig build run -Drelease -- -i "https://w.wallhaven.cc/full/85/wallhaven-856dlk.png" -o ascii.png -e -c --full_characters --sorted_ovr



================================================
File: build.zig
================================================
const std = @import("std");
const Build = std.Build;
const Module = Build.Module;
const Version = std.SemanticVersion;

fn getEnvOrDefault(b: *std.Build, name: []const u8, default_value: []const u8) []const u8 {
    const v = std.process.getEnvVarOwned(b.allocator, name) catch {
        return default_value;
    };
    return v;
}

const BuildOptions = struct {
    libglyph: *Module,
    stb: *Module,
    term: *Module,
    libav: *Module,
    video: *Module,
    img: *Module,
    version: Version,
};

pub fn build(b: *std.Build) !void {
    const optimize = b.standardOptimizeOption(.{});
    const strip = b.option(bool, "strip", "Omit debug information") orelse false;
    const target = b.standardTargetOptions(.{});
    const dep_stb = b.dependency("stb", .{});

    const version = try Version.parse("1.0.11");

    const stb_module = b.addModule("stb", .{
        .root_source_file = b.path("vendor/stb.zig"),
        .target = target,
        .optimize = optimize,
    });
    stb_module.addIncludePath(dep_stb.path(""));
    stb_module.addCSourceFile(.{ .file = b.path("vendor/stb.c") });
    const av_module = b.addModule("av", .{
        .root_source_file = b.path("vendor/av.zig"),
        .target = target,
        .optimize = optimize,
    });
    linkFfmpeg(b, target, av_module);
    const libglyph = b.addModule("libglyph", .{
        .root_source_file = b.path("src/core.zig"),
        .target = target,
        .optimize = optimize,
        .imports = &.{
            .{ .name = "stb", .module = stb_module },
        },
    });

    const term_module = b.addModule("libglyphterm", .{
        .root_source_file = b.path("src/term.zig"),
        .target = target,
        .optimize = optimize,
        .imports = &.{
            .{ .name = "libglyph", .module = libglyph },
        },
    });
    const video_module = b.addModule("libglyphav", .{
        .root_source_file = b.path("src/video.zig"),
        .target = target,
        .optimize = optimize,
        .imports = &.{
            .{ .name = "stb", .module = stb_module },
            .{ .name = "av", .module = av_module },
            .{ .name = "libglyph", .module = libglyph },
            .{ .name = "libglyphterm", .module = term_module },
        },
    });
    const image_module = b.addModule("libglyphimg", .{
        .root_source_file = b.path("src/image.zig"),
        .imports = &.{
            .{ .name = "stb", .module = stb_module },
            .{ .name = "av", .module = av_module },
            .{ .name = "libglyph", .module = libglyph },
            .{ .name = "libglyphterm", .module = term_module },
        },
    });

    const buildOpts = &BuildOptions{
        .libglyph = libglyph,
        .stb = stb_module,
        .term = term_module,
        .img = image_module,
        .libav = av_module,
        .video = video_module,
        .version = version,
    };

    try runZig(
        buildOpts,
        b,
        target,
        optimize,
        strip,
    );
}

fn setupExecutable(
    self: *const BuildOptions,
    b: *std.Build,
    name: []const u8,
    target: std.Build.ResolvedTarget,
    optimize: std.builtin.OptimizeMode,
    strip: bool,
    link_libc: bool,
) !*std.Build.Step.Compile {
    const exe = b.addExecutable(.{
        .name = name,
        .root_source_file = b.path("src/main.zig"),
        .target = target,
        .optimize = optimize,
        .strip = strip,
        .link_libc = link_libc,
    });
    exe.root_module.addImport("build_options", buildOptionsModule(self, b));

    const clap = b.dependency("clap", .{});
    exe.root_module.addImport("clap", clap.module("clap"));
    exe.root_module.addImport("libglyph", self.libglyph);
    exe.root_module.addImport("libglyphimg", self.img);
    exe.root_module.addImport("libglyphav", self.video);
    exe.root_module.addImport("libglyphterm", self.term);

    return exe;
}

fn setupTest(
    self: *const BuildOptions,
    b: *std.Build,
    target: std.Build.ResolvedTarget,
    optimize: std.builtin.OptimizeMode,
    strip: bool,
) !*std.Build.Step.Compile {
    const unit_test = b.addTest(.{
        .root_source_file = b.path("src/tests.zig"),
        .target = target,
        .optimize = optimize,
        .strip = strip,
        .link_libc = true,
    });
    unit_test.root_module.addImport("build_options", buildOptionsModule(self, b));

    const clap = b.dependency("clap", .{});
    unit_test.root_module.addImport("clap", clap.module("clap"));
    unit_test.root_module.addImport("libglyph", self.libglyph);
    unit_test.root_module.addImport("libglyphimg", self.img);
    unit_test.root_module.addImport("libglyphav", self.video);
    unit_test.root_module.addImport("libglyphterm", self.term);

    return unit_test;
}

fn linkFfmpeg(b: *std.Build, target: std.Build.ResolvedTarget, lib: *Module) void {
    if (target.result.os.tag == .windows) {
        const ffmpeg_include_path = getEnvOrDefault(b, "INCLUDE", "C:/ProgramData/chocolatey/lib/ffmpeg-shared/tools/ffmpeg-7.1-full_build-shared/include");
        const ffmpeg_lib_path = getEnvOrDefault(b, "LIB", "C:/ProgramData/chocolatey/lib/ffmpeg-shared/tools/ffmpeg-7.1-full_build-shared/lib");

        lib.addLibraryPath(.{ .cwd_relative = ffmpeg_lib_path });
        lib.addIncludePath(.{ .cwd_relative = ffmpeg_include_path });
        lib.linkSystemLibrary("avformat", .{});
        lib.linkSystemLibrary("avcodec", .{});
        lib.linkSystemLibrary("avutil", .{});
        lib.linkSystemLibrary("swscale", .{});
        lib.linkSystemLibrary("swresample", .{});
    } else {
        lib.linkSystemLibrary("libavformat", .{ .use_pkg_config = .force });
        lib.linkSystemLibrary("libavcodec", .{ .use_pkg_config = .force });
        lib.linkSystemLibrary("libavutil", .{ .use_pkg_config = .force });
        lib.linkSystemLibrary("libswscale", .{ .use_pkg_config = .force });
        lib.linkSystemLibrary("libswresample", .{ .use_pkg_config = .force });
    }
}

fn runZig(
    self: *const BuildOptions,
    b: *std.Build,
    target: std.Build.ResolvedTarget,
    optimize: std.builtin.OptimizeMode,
    strip: bool,
) !void {
    const exe = try setupExecutable(
        self,
        b,
        "glyph",
        target,
        optimize,
        strip,
        true,
    );

    const exe_check = try setupExecutable(
        self,
        b,
        "glyph-check",
        target,
        optimize,
        strip,
        false,
    );
    const check_step = b.step("check", "Run the check");
    check_step.dependOn(&exe_check.step);

    b.installArtifact(exe);

    const run_cmd = b.addRunArtifact(exe);
    run_cmd.step.dependOn(b.getInstallStep());

    if (b.args) |args| run_cmd.addArgs(args);

    const run_step = b.step("run", "Run the app");
    run_step.dependOn(&run_cmd.step);

    const test_step = b.step("test", "Run unit tests");
    const unit_tests = try setupTest(
        self,
        b,
        target,
        optimize,
        strip,
    );
    const run_unit_tests = b.addRunArtifact(unit_tests);
    test_step.dependOn(&run_unit_tests.step);
}

fn buildOptionsModule(self: *const BuildOptions, b: *std.Build) *Module {
    var opts = b.addOptions();

    opts.addOption(std.SemanticVersion, "version", self.version);

    const mod = opts.createModule();
    return mod;
}



================================================
File: build.zig.zon
================================================
.{
    .name = .glyph,
    .version = "1.0.11",
    .minimum_zig_version = "0.14.0",
    .dependencies = .{
        .clap = .{
            .url = "https://github.com/Hejsil/zig-clap/archive/refs/tags/0.10.0.tar.gz",
            .hash = "clap-0.10.0-oBajB434AQBDh-Ei3YtoKIRxZacVPF1iSwp3IX_ZB8f0",
        },
        .stb = .{
            .url = "git+https://github.com/nothings/stb.git?ref=master#f75e8d1cad7d90d72ef7a4661f1b994ef78b4e31",
            .hash = "1220c4fe5a4c4ebec402f5cdef08bc264b56fb07f259107d2b01ba8d416d88624b50",
        },
    },
    .paths = .{
        "",
    },
    .fingerprint = 0xabb6d7b897c46453,
}



================================================
File: LICENSE
================================================
MIT License

Copyright (c) 2024 seatedro

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.



================================================
File: src/bitmap.zig
================================================
const std = @import("std");

/// Author: Daniel Hepper <daniel@hepper.net>
/// URL: https://github.com/dhepper/font8x8
pub const font8x8_basic: [128][8]u8 = .{
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0000 (null)
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0001
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0002
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0003
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0004
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0005
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0006
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0007
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0008
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0009
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+000A
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+000B
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+000C
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+000D
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+000E
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+000F
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0010
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0011
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0012
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0013
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0014
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0015
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0016
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0017
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0018
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0019
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+001A
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+001B
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+001C
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+001D
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+001E
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+001F
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0020 (space)
    .{ 0x18, 0x3C, 0x3C, 0x18, 0x18, 0x00, 0x18, 0x00 }, // U+0021 (!)
    .{ 0x6C, 0x6C, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0022 (")
    .{ 0x6C, 0x6C, 0xFE, 0x6C, 0xFE, 0x6C, 0x6C, 0x00 }, // U+0023 (#)
    .{ 0x30, 0x7C, 0xC0, 0x78, 0x0C, 0xF8, 0x30, 0x00 }, // U+0024 ($)
    .{ 0x00, 0xC6, 0xCC, 0x18, 0x30, 0x66, 0xC6, 0x00 }, // U+0025 (%)
    .{ 0x38, 0x6C, 0x38, 0x76, 0xDC, 0xCC, 0x76, 0x00 }, // U+0026 (&)
    .{ 0x60, 0x60, 0xC0, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0027 (')
    .{ 0x18, 0x30, 0x60, 0x60, 0x60, 0x30, 0x18, 0x00 }, // U+0028 (()
    .{ 0x60, 0x30, 0x18, 0x18, 0x18, 0x30, 0x60, 0x00 }, // U+0029 ())
    .{ 0x00, 0x66, 0x3C, 0xFF, 0x3C, 0x66, 0x00, 0x00 }, // U+002A (*)
    .{ 0x00, 0x30, 0x30, 0xFC, 0x30, 0x30, 0x00, 0x00 }, // U+002B (+)
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x30, 0x30, 0x60 }, // U+002C (,)
    .{ 0x00, 0x00, 0x00, 0xFC, 0x00, 0x00, 0x00, 0x00 }, // U+002D (-)
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x30, 0x30, 0x00 }, // U+002E (.)
    .{ 0x06, 0x0C, 0x18, 0x30, 0x60, 0xC0, 0x80, 0x00 }, // U+002F (/)
    .{ 0x7C, 0xC6, 0xCE, 0xDE, 0xF6, 0xE6, 0x7C, 0x00 }, // U+0030 (0)
    .{ 0x30, 0x70, 0x30, 0x30, 0x30, 0x30, 0xFC, 0x00 }, // U+0031 (1)
    .{ 0x78, 0xCC, 0x0C, 0x38, 0x60, 0xCC, 0xFC, 0x00 }, // U+0032 (2)
    .{ 0x78, 0xCC, 0x0C, 0x38, 0x0C, 0xCC, 0x78, 0x00 }, // U+0033 (3)
    .{ 0x1C, 0x3C, 0x6C, 0xCC, 0xFE, 0x0C, 0x1E, 0x00 }, // U+0034 (4)
    .{ 0xFC, 0xC0, 0xF8, 0x0C, 0x0C, 0xCC, 0x78, 0x00 }, // U+0035 (5)
    .{ 0x38, 0x60, 0xC0, 0xF8, 0xCC, 0xCC, 0x78, 0x00 }, // U+0036 (6)
    .{ 0xFC, 0xCC, 0x0C, 0x18, 0x30, 0x30, 0x30, 0x00 }, // U+0037 (7)
    .{ 0x78, 0xCC, 0xCC, 0x78, 0xCC, 0xCC, 0x78, 0x00 }, // U+0038 (8)
    .{ 0x78, 0xCC, 0xCC, 0x7C, 0x0C, 0x18, 0x70, 0x00 }, // U+0039 (9)
    .{ 0x00, 0x30, 0x30, 0x00, 0x00, 0x30, 0x30, 0x00 }, // U+003A (:)
    .{ 0x00, 0x30, 0x30, 0x00, 0x00, 0x30, 0x30, 0x60 }, // U+003B (;)
    .{ 0x18, 0x30, 0x60, 0xC0, 0x60, 0x30, 0x18, 0x00 }, // U+003C (<)
    .{ 0x00, 0x00, 0xFC, 0x00, 0x00, 0xFC, 0x00, 0x00 }, // U+003D (=)
    .{ 0x60, 0x30, 0x18, 0x0C, 0x18, 0x30, 0x60, 0x00 }, // U+003E (>)
    .{ 0x78, 0xCC, 0x0C, 0x18, 0x30, 0x00, 0x30, 0x00 }, // U+003F (?)
    .{ 0x7C, 0xC6, 0xDE, 0xDE, 0xDE, 0xC0, 0x78, 0x00 }, // U+0040 (@)
    .{ 0x30, 0x78, 0xCC, 0xCC, 0xFC, 0xCC, 0xCC, 0x00 }, // U+0041 (A)
    .{ 0xFC, 0x66, 0x66, 0x7C, 0x66, 0x66, 0xFC, 0x00 }, // U+0042 (B)
    .{ 0x3C, 0x66, 0xC0, 0xC0, 0xC0, 0x66, 0x3C, 0x00 }, // U+0043 (C)
    .{ 0xF8, 0x6C, 0x66, 0x66, 0x66, 0x6C, 0xF8, 0x00 }, // U+0044 (D)
    .{ 0xFE, 0x62, 0x68, 0x78, 0x68, 0x62, 0xFE, 0x00 }, // U+0045 (E)
    .{ 0xFE, 0x62, 0x68, 0x78, 0x68, 0x60, 0xF0, 0x00 }, // U+0046 (F)
    .{ 0x3C, 0x66, 0xC0, 0xC0, 0xCE, 0x66, 0x3E, 0x00 }, // U+0047 (G)
    .{ 0xCC, 0xCC, 0xCC, 0xFC, 0xCC, 0xCC, 0xCC, 0x00 }, // U+0048 (H)
    .{ 0x78, 0x30, 0x30, 0x30, 0x30, 0x30, 0x78, 0x00 }, // U+0049 (I)
    .{ 0x1E, 0x0C, 0x0C, 0x0C, 0xCC, 0xCC, 0x78, 0x00 }, // U+004A (J)
    .{ 0xE6, 0x66, 0x6C, 0x78, 0x6C, 0x66, 0xE6, 0x00 }, // U+004B (K)
    .{ 0xF0, 0x60, 0x60, 0x60, 0x62, 0x66, 0xFE, 0x00 }, // U+004C (L)
    .{ 0xC6, 0xEE, 0xFE, 0xFE, 0xD6, 0xC6, 0xC6, 0x00 }, // U+004D (M)
    .{ 0xC6, 0xE6, 0xF6, 0xDE, 0xCE, 0xC6, 0xC6, 0x00 }, // U+004E (N)
    .{ 0x38, 0x6C, 0xC6, 0xC6, 0xC6, 0x6C, 0x38, 0x00 }, // U+004F (O)
    .{ 0xFC, 0x66, 0x66, 0x7C, 0x60, 0x60, 0xF0, 0x00 }, // U+0050 (P)
    .{ 0x78, 0xCC, 0xCC, 0xCC, 0xDC, 0x78, 0x1C, 0x00 }, // U+0051 (Q)
    .{ 0xFC, 0x66, 0x66, 0x7C, 0x6C, 0x66, 0xE6, 0x00 }, // U+0052 (R)
    .{ 0x78, 0xCC, 0xE0, 0x70, 0x1C, 0xCC, 0x78, 0x00 }, // U+0053 (S)
    .{ 0xFC, 0xB4, 0x30, 0x30, 0x30, 0x30, 0x78, 0x00 }, // U+0054 (T)
    .{ 0xCC, 0xCC, 0xCC, 0xCC, 0xCC, 0xCC, 0xFC, 0x00 }, // U+0055 (U)
    .{ 0xCC, 0xCC, 0xCC, 0xCC, 0xCC, 0x78, 0x30, 0x00 }, // U+0056 (V)
    .{ 0xC6, 0xC6, 0xC6, 0xD6, 0xFE, 0xEE, 0xC6, 0x00 }, // U+0057 (W)
    .{ 0xC6, 0xC6, 0x6C, 0x38, 0x38, 0x6C, 0xC6, 0x00 }, // U+0058 (X)
    .{ 0xCC, 0xCC, 0xCC, 0x78, 0x30, 0x30, 0x78, 0x00 }, // U+0059 (Y)
    .{ 0xFE, 0xC6, 0x8C, 0x18, 0x32, 0x66, 0xFE, 0x00 }, // U+005A (Z)
    .{ 0x78, 0x60, 0x60, 0x60, 0x60, 0x60, 0x78, 0x00 }, // U+005B ([)
    .{ 0xC0, 0x60, 0x30, 0x18, 0x0C, 0x06, 0x02, 0x00 }, // U+005C (\)
    .{ 0x78, 0x18, 0x18, 0x18, 0x18, 0x18, 0x78, 0x00 }, // U+005D (])
    .{ 0x10, 0x38, 0x6C, 0xC6, 0x00, 0x00, 0x00, 0x00 }, // U+005E (^)
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xFF }, // U+005F (_)
    .{ 0x30, 0x30, 0x18, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+0060 (`)
    .{ 0x00, 0x00, 0x78, 0x0C, 0x7C, 0xCC, 0x76, 0x00 }, // U+0061 (a)
    .{ 0xE0, 0x60, 0x60, 0x7C, 0x66, 0x66, 0xDC, 0x00 }, // U+0062 (b)
    .{ 0x00, 0x00, 0x78, 0xCC, 0xC0, 0xCC, 0x78, 0x00 }, // U+0063 (c)
    .{ 0x1C, 0x0C, 0x0C, 0x7C, 0xCC, 0xCC, 0x76, 0x00 }, // U+0064 (d)
    .{ 0x00, 0x00, 0x78, 0xCC, 0xFC, 0xC0, 0x78, 0x00 }, // U+0065 (e)
    .{ 0x38, 0x6C, 0x60, 0xF0, 0x60, 0x60, 0xF0, 0x00 }, // U+0066 (f)
    .{ 0x00, 0x00, 0x76, 0xCC, 0xCC, 0x7C, 0x0C, 0xF8 }, // U+0067 (g)
    .{ 0xE0, 0x60, 0x6C, 0x76, 0x66, 0x66, 0xE6, 0x00 }, // U+0068 (h)
    .{ 0x30, 0x00, 0x70, 0x30, 0x30, 0x30, 0x78, 0x00 }, // U+0069 (i)
    .{ 0x0C, 0x00, 0x0C, 0x0C, 0x0C, 0xCC, 0xCC, 0x78 }, // U+006A (j)
    .{ 0xE0, 0x60, 0x66, 0x6C, 0x78, 0x6C, 0xE6, 0x00 }, // U+006B (k)
    .{ 0x70, 0x30, 0x30, 0x30, 0x30, 0x30, 0x78, 0x00 }, // U+006C (l)
    .{ 0x00, 0x00, 0xCC, 0xFE, 0xFE, 0xD6, 0xC6, 0x00 }, // U+006D (m)
    .{ 0x00, 0x00, 0xF8, 0xCC, 0xCC, 0xCC, 0xCC, 0x00 }, // U+006E (n)
    .{ 0x00, 0x00, 0x78, 0xCC, 0xCC, 0xCC, 0x78, 0x00 }, // U+006F (o)
    .{ 0x00, 0x00, 0xDC, 0x66, 0x66, 0x7C, 0x60, 0xF0 }, // U+0070 (p)
    .{ 0x00, 0x00, 0x76, 0xCC, 0xCC, 0x7C, 0x0C, 0x1E }, // U+0071 (q)
    .{ 0x00, 0x00, 0xDC, 0x76, 0x66, 0x60, 0xF0, 0x00 }, // U+0072 (r)
    .{ 0x00, 0x00, 0x7C, 0xC0, 0x78, 0x0C, 0xF8, 0x00 }, // U+0073 (s)
    .{ 0x10, 0x30, 0x7C, 0x30, 0x30, 0x34, 0x18, 0x00 }, // U+0074 (t)
    .{ 0x00, 0x00, 0xCC, 0xCC, 0xCC, 0xCC, 0x76, 0x00 }, // U+0075 (u)
    .{ 0x00, 0x00, 0xCC, 0xCC, 0xCC, 0x78, 0x30, 0x00 }, // U+0076 (v)
    .{ 0x00, 0x00, 0xC6, 0xD6, 0xFE, 0xFE, 0x6C, 0x00 }, // U+0077 (w)
    .{ 0x00, 0x00, 0xC6, 0x6C, 0x38, 0x6C, 0xC6, 0x00 }, // U+0078 (x)
    .{ 0x00, 0x00, 0xCC, 0xCC, 0xCC, 0x7C, 0x0C, 0xF8 }, // U+0079 (y)
    .{ 0x00, 0x00, 0xFC, 0x98, 0x30, 0x64, 0xFC, 0x00 }, // U+007A (z)
    .{ 0x1C, 0x30, 0x30, 0xE0, 0x30, 0x30, 0x1C, 0x00 }, // U+007B ({)
    .{ 0x18, 0x18, 0x18, 0x00, 0x18, 0x18, 0x18, 0x00 }, // U+007C (|)
    .{ 0xE0, 0x30, 0x30, 0x1C, 0x30, 0x30, 0xE0, 0x00 }, // U+007D (})
    .{ 0x76, 0xDC, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+007E (~)
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+007F
};

/// Contains an 8x8 font map for unicode points U+2580 - U+259F (block elements)
/// Author: Daniel Hepper <daniel@hepper.net>
/// URL: https://github.com/dhepper/font8x8
pub const font8x8_block: [32][8]u8 = .{
    .{ 0xFF, 0xFF, 0xFF, 0xFF, 0x00, 0x00, 0x00, 0x00 }, // U+2580 (top half)
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xFF }, // U+2581 (box 1/8)
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xFF, 0xFF }, // U+2582 (box 2/8)
    .{ 0x00, 0x00, 0x00, 0x00, 0x00, 0xFF, 0xFF, 0xFF }, // U+2583 (box 3/8)
    .{ 0x00, 0x00, 0x00, 0x00, 0xFF, 0xFF, 0xFF, 0xFF }, // U+2584 (bottom half)
    .{ 0x00, 0x00, 0x00, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF }, // U+2585 (box 5/8)
    .{ 0x00, 0x00, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF }, // U+2586 (box 6/8)
    .{ 0x00, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF }, // U+2587 (box 7/8)
    .{ 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF }, // U+2588 (solid)
    .{ 0x7F, 0x7F, 0x7F, 0x7F, 0x7F, 0x7F, 0x7F, 0x7F }, // U+2589 (box 7/8)
    .{ 0x3F, 0x3F, 0x3F, 0x3F, 0x3F, 0x3F, 0x3F, 0x3F }, // U+258A (box 6/8)
    .{ 0x1F, 0x1F, 0x1F, 0x1F, 0x1F, 0x1F, 0x1F, 0x1F }, // U+258B (box 5/8)
    .{ 0x0F, 0x0F, 0x0F, 0x0F, 0x0F, 0x0F, 0x0F, 0x0F }, // U+258C (left half)
    .{ 0x07, 0x07, 0x07, 0x07, 0x07, 0x07, 0x07, 0x07 }, // U+258D (box 3/8)
    .{ 0x03, 0x03, 0x03, 0x03, 0x03, 0x03, 0x03, 0x03 }, // U+258E (box 2/8)
    .{ 0x01, 0x01, 0x01, 0x01, 0x01, 0x01, 0x01, 0x01 }, // U+258F (box 1/8)
    .{ 0xF0, 0xF0, 0xF0, 0xF0, 0xF0, 0xF0, 0xF0, 0xF0 }, // U+2590 (right half)
    .{ 0x55, 0x00, 0xAA, 0x00, 0x55, 0x00, 0xAA, 0x00 }, // U+2591 (25% solid)
    .{ 0x55, 0xAA, 0x55, 0xAA, 0x55, 0xAA, 0x55, 0xAA }, // U+2592 (50% solid)
    .{ 0xFF, 0xAA, 0xFF, 0x55, 0xFF, 0xAA, 0xFF, 0x55 }, // U+2593 (75% solid)
    .{ 0xFF, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00 }, // U+2594 (box 1/8)
    .{ 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80 }, // U+2595 (box 1/8)
    .{ 0x00, 0x00, 0x00, 0x00, 0x0F, 0x0F, 0x0F, 0x0F }, // U+2596 (box bottom left)
    .{ 0x00, 0x00, 0x00, 0x00, 0xF0, 0xF0, 0xF0, 0xF0 }, // U+2597 (box bottom right)
    .{ 0x0F, 0x0F, 0x0F, 0x0F, 0x00, 0x00, 0x00, 0x00 }, // U+2598 (box top left)
    .{ 0x0F, 0x0F, 0x0F, 0x0F, 0xFF, 0xFF, 0xFF, 0xFF }, // U+2599 (boxes left and bottom)
    .{ 0x0F, 0x0F, 0x0F, 0x0F, 0xF0, 0xF0, 0xF0, 0xF0 }, // U+259A (boxes top-left and bottom right)
    .{ 0xFF, 0xFF, 0xFF, 0xFF, 0x0F, 0x0F, 0x0F, 0x0F }, // U+259B (boxes top and left)
    .{ 0xFF, 0xFF, 0xFF, 0xFF, 0xF0, 0xF0, 0xF0, 0xF0 }, // U+259C (boxes top and right)
    .{ 0xF0, 0xF0, 0xF0, 0xF0, 0x00, 0x00, 0x00, 0x00 }, // U+259D (box top right)
    .{ 0xF0, 0xF0, 0xF0, 0xF0, 0x0F, 0x0F, 0x0F, 0x0F }, // U+259E (boxes top right and bottom left)
    .{ 0xF0, 0xF0, 0xF0, 0xF0, 0xFF, 0xFF, 0xFF, 0xFF }, // U+259F (boxes right and bottom)
};

pub fn getCharSet(bytes: []const u8) ![8]u8 {
    const char = try std.unicode.utf8Decode(bytes);
    // 0x2580 is the first block character
    if (char > 0x2580 and char <= 0x259F) {
        return font8x8_block[char - 0x2580];
    }
    if (char >= 0 and char <= 0x007F) {
        return font8x8_basic[char];
    }
    std.debug.print("Character: {any}\n", .{char});
    return error.InvalidChar;
}



================================================
File: src/core.zig
================================================
const std = @import("std");
pub const bitmap = @import("bitmap.zig");
pub const stb = @import("stb");

pub const OutputType = enum {
    Stdout,
    Text,
    Image,
    Video,
};

pub const SymbolType = enum {
    Ascii,
    Block,
};

pub const Image = struct {
    data: []u8,
    width: usize,
    height: usize,
    channels: usize,
};

const SobelFilter = struct {
    magnitude: []f32,
    direction: []f32,
};

pub const EdgeData = struct {
    grayscale: []u8,
    magnitude: []f32,
    direction: []f32,
};

pub const DitherType = enum { FloydSteinberg, None };

pub const CoreParams = struct {
    input: []const u8,
    output: ?[]const u8,
    color: bool,
    invert_color: bool,
    scale: f32,
    brightness_boost: f32,
    auto_adjust: bool,
    ascii_chars: []const u8,
    ascii_info: []AsciiCharInfo,
    block_size: u8,
    stretched: bool,
    output_type: OutputType,
    detect_edges: bool,
    threshold_disabled: bool,
    sigma1: f32,
    sigma2: f32,
    frame_rate: ?f32,
    ffmpeg_options: std.StringHashMap([]const u8),
    keep_audio: bool,
    codec: ?[]const u8,
    dither: ?DitherType,
    bg_color: ?[3]u8,
    fg_color: ?[3]u8,

    pub fn deinit(self: *CoreParams) void {
        var it = self.ffmpeg_options.iterator();
        while (it.next()) |entry| {
            self.ffmpeg_options.allocator.free(entry.key_ptr.*);
            self.ffmpeg_options.allocator.free(entry.value_ptr.*);
        }
        self.ffmpeg_options.deinit();
    }
};

pub const AsciiCharInfo = struct { start: usize, len: u8 };

// -----------------------
// CORE GLYPH FUNCTIONS
// -----------------------

pub fn initAsciiChars(allocator: std.mem.Allocator, ascii_chars: []const u8) ![]AsciiCharInfo {
    var char_info = std.ArrayList(AsciiCharInfo).init(allocator);
    defer char_info.deinit();

    var i: usize = 0;
    while (i < ascii_chars.len) {
        const len = try std.unicode.utf8ByteSequenceLength(ascii_chars[i]);
        try char_info.append(.{ .start = i, .len = @intCast(len) });
        i += len;
    }

    return char_info.toOwnedSlice();
}

pub fn selectAsciiChar(block_info: BlockInfo, args: CoreParams) []const u8 {
    const avg_brightness: usize = @intCast(block_info.sum_brightness / block_info.pixel_count);
    const boosted_brightness: usize = @intFromFloat(@as(f32, @floatFromInt(avg_brightness)) * args.brightness_boost);
    const clamped_brightness = std.math.clamp(boosted_brightness, 0, 255);

    if (args.detect_edges) {
        const avg_mag: f32 = block_info.sum_mag / @as(f32, @floatFromInt(block_info.pixel_count));
        const avg_dir: f32 = block_info.sum_dir / @as(f32, @floatFromInt(block_info.pixel_count));
        if (getEdgeChar(avg_mag, avg_dir, args.threshold_disabled)) |ec| {
            return &[_]u8{ec};
        }
    }

    if (clamped_brightness == 0) return " ";

    const char_index = (clamped_brightness * args.ascii_chars.len) / 256;
    const selected_char = args.ascii_info[@min(char_index, args.ascii_info.len - 1)];
    return args.ascii_chars[selected_char.start .. selected_char.start + selected_char.len];
}

pub fn rgbToGrayScale(allocator: std.mem.Allocator, img: Image) ![]u8 {
    const grayscale_img = try allocator.alloc(u8, img.width * img.height);
    errdefer allocator.free(grayscale_img);

    for (0..img.height) |y| {
        for (0..img.width) |x| {
            const i = (y * img.width + x) * img.channels;
            if (i + 2 >= img.width * img.height * img.channels) {
                continue; // Skip if accessing out of bounds
            }
            const r = img.data[i];
            const g = img.data[i + 1];
            const b = img.data[i + 2];
            grayscale_img[y * img.width + x] = @intFromFloat((0.299 * @as(f32, @floatFromInt(r)) +
                0.587 * @as(f32, @floatFromInt(g)) +
                0.114 * @as(f32, @floatFromInt(b))));
        }
    }
    return grayscale_img;
}

pub fn resizeImage(allocator: std.mem.Allocator, img: Image, new_width: usize, new_height: usize) !Image {
    // Safety checks
    if (img.width == 0 or img.height == 0 or new_width == 0 or new_height == 0) {
        return error.InvalidDimensions;
    }

    const total_pixels = new_width * new_height;
    const buffer_size = total_pixels * img.channels;

    const scaled_data = try allocator.alloc(u8, buffer_size);
    errdefer allocator.free(scaled_data);

    const result = stb.stbir_resize_uint8_linear(
        img.data.ptr,
        @intCast(img.width),
        @intCast(img.height),
        0,
        scaled_data.ptr,
        @intCast(new_width),
        @intCast(new_height),
        0,
        @intCast(img.channels),
    );

    if (result == 0) {
        return error.ImageResizeFailed;
    }

    return Image{
        .data = scaled_data,
        .width = new_width,
        .height = new_height,
        .channels = img.channels,
    };
}

pub fn autoBrightnessContrast(
    allocator: std.mem.Allocator,
    img: Image,
    clip_hist_percent: f32,
) ![]u8 {
    const gray = try rgbToGrayScale(allocator, img);
    defer allocator.free(gray);

    // Calculate histogram / frequency distribution
    var hist = [_]usize{0} ** 256;
    for (gray) |px| {
        hist[px] += 1;
    }

    // Cumulative distribution
    var accumulator = [_]usize{0} ** 256;
    accumulator[0] = hist[0];
    for (1..256) |i| {
        accumulator[i] = accumulator[i - 1] + hist[i];
    }

    // Locate points to clip
    const max = accumulator[255];
    const clip_hist_count = @as(usize, @intFromFloat(@as(f32, @floatFromInt(max)) * clip_hist_percent / 100.0 / 2.0));

    // Locate left cut
    var min_gray: usize = 0;
    while (accumulator[min_gray] < clip_hist_count) : (min_gray += 1) {}

    // Locate right cut
    var max_gray: usize = 255;
    while (accumulator[max_gray] >= (max - clip_hist_count)) : (max_gray -= 1) {}

    // Calculate alpha and beta values
    const alpha = 255.0 / @as(f32, @floatFromInt(max_gray - min_gray));
    const beta = -@as(f32, @floatFromInt(min_gray)) * alpha;

    // Apply brightness and contrast adjustment
    const len = img.width * img.height * img.channels;
    var res = try allocator.alloc(u8, len);
    for (0..len) |i| {
        const adjusted = @as(f32, @floatFromInt(img.data[i])) * alpha + beta;
        res[i] = @intFromFloat(std.math.clamp(adjusted, 0, 255));
    }

    return res;
}

pub fn gaussianKernel(allocator: std.mem.Allocator, sigma: f32) ![]f32 {
    const size: usize = @intFromFloat(6 * sigma);
    const kernel_size = if (size % 2 == 0) size + 1 else size;
    const half: f32 = @floatFromInt(kernel_size / 2);

    var kernel = try allocator.alloc(f32, kernel_size);
    var sum: f32 = 0;

    for (0..kernel_size) |i| {
        const x = @as(f32, @floatFromInt(i)) - half;
        kernel[i] = @exp(-(x * x) / (2 * sigma * sigma));
        sum += kernel[i];
    }

    // Normalize the kernel
    for (0..kernel_size) |i| {
        kernel[i] /= sum;
    }

    return kernel;
}

pub fn applyGaussianBlur(allocator: std.mem.Allocator, img: Image, sigma: f32) ![]u8 {
    const kernel = try gaussianKernel(allocator, sigma);
    defer allocator.free(kernel);

    var temp = try allocator.alloc(u8, img.width * img.height);
    defer allocator.free(temp);
    var res = try allocator.alloc(u8, img.width * img.height);

    // Horizontal pass
    for (0..img.height) |y| {
        for (0..img.width) |x| {
            var sum: f32 = 0;
            for (0..kernel.len) |i| {
                const ix: i32 = @as(i32, @intCast(x)) + @as(i32, @intCast(i)) - @as(i32, @intCast(kernel.len / 2));
                if (ix >= 0 and ix < img.width) {
                    sum += @as(f32, @floatFromInt(img.data[y * img.width + @as(usize, @intCast(ix))])) * kernel[i];
                }
            }
            temp[y * img.width + x] = @intFromFloat(sum);
        }
    }

    // Vertical pass
    for (0..img.height) |y| {
        for (0..img.width) |x| {
            var sum: f32 = 0;
            for (0..kernel.len) |i| {
                const iy: i32 = @as(i32, @intCast(y)) + @as(i32, @intCast(i)) - @as(i32, @intCast(kernel.len / 2));
                if (iy >= 0 and iy < img.height) {
                    sum += @as(f32, @floatFromInt(temp[@as(usize, @intCast(iy)) * img.width + x])) * kernel[i];
                }
            }
            res[y * img.width + x] = @intFromFloat(sum);
        }
    }

    return res;
}

pub fn differenceOfGaussians(allocator: std.mem.Allocator, img: Image, sigma1: f32, sigma2: f32) ![]u8 {
    const blur1 = try applyGaussianBlur(allocator, img, sigma1);
    defer allocator.free(blur1);
    const blur2 = try applyGaussianBlur(allocator, img, sigma2);
    defer allocator.free(blur2);

    var res = try allocator.alloc(u8, img.width * img.height);
    for (0..img.width * img.height) |i| {
        const diff = @as(i16, blur1[i]) - @as(i16, blur2[i]);
        res[i] = @as(u8, @intCast(std.math.clamp(diff + 128, 0, 255)));
    }

    return res;
}

pub fn applySobelFilter(allocator: std.mem.Allocator, img: Image) !SobelFilter {
    const Gx = [_][3]i32{ .{ -1, 0, 1 }, .{ -2, 0, 2 }, .{ -1, 0, 1 } };
    const Gy = [_][3]i32{ .{ -1, -2, -1 }, .{ 0, 0, 0 }, .{ 1, 2, 1 } };

    var mag = try allocator.alloc(f32, img.width * img.height);
    errdefer allocator.free(mag);

    var dir = try allocator.alloc(f32, img.width * img.height);
    errdefer allocator.free(dir);

    // Initialize arrays to avoid uninitialized memory
    @memset(mag, 0);
    @memset(dir, 0);

    // Skip edge processing if image is too small
    if (img.width < 3 or img.height < 3) {
        return SobelFilter{
            .magnitude = mag,
            .direction = dir,
        };
    }

    // Handle bounds to prevent integer overflow
    const height_max = if (img.height > 0) img.height - 1 else 0;
    const width_max = if (img.width > 0) img.width - 1 else 0;

    // Process the inner part of the image (skip borders)
    var y: usize = 1;
    while (y < height_max) : (y += 1) {
        var x: usize = 1;
        while (x < width_max) : (x += 1) {
            var gx: f32 = 0;
            var gy: f32 = 0;

            for (0..3) |i| {
                for (0..3) |j| {
                    const pixel_idx = (y + i - 1) * img.width + (x + j - 1);
                    if (pixel_idx < img.width * img.height) {
                        const pixel = img.data[pixel_idx];
                        gx += @as(f32, @floatFromInt(Gx[i][j])) * @as(f32, @floatFromInt(pixel));
                        gy += @as(f32, @floatFromInt(Gy[i][j])) * @as(f32, @floatFromInt(pixel));
                    }
                }
            }

            const idx = y * img.width + x;
            if (idx < img.width * img.height) {
                mag[idx] = @sqrt(gx * gx + gy * gy);
                dir[idx] = std.math.atan2(gy, gx);
            }
        }
    }

    return SobelFilter{
        .magnitude = mag,
        .direction = dir,
    };
}

pub fn getEdgeChar(mag: f32, dir: f32, threshold_disabled: bool) ?u8 {
    const threshold: f32 = 50;
    if (mag < threshold and !threshold_disabled) {
        return null;
    }

    const angle = (dir + std.math.pi) * (@as(f32, 180) / std.math.pi);
    return switch (@as(u8, @intFromFloat(@mod(angle + 22.5, 180) / 45))) {
        0, 4 => '-',
        1, 5 => '\\',
        2, 6 => '|',
        3, 7 => '/',
        else => unreachable,
    };
}

pub fn detectEdges(allocator: std.mem.Allocator, img: Image, detect_edges: bool, sigma1: f32, sigma2: f32) !?EdgeData {
    if (!detect_edges) {
        return null;
    }

    // Handle invalid image dimensions
    if (img.width == 0 or img.height == 0) {
        const empty_u8 = try allocator.alloc(u8, 0);
        const empty_f32_1 = try allocator.alloc(f32, 0);
        const empty_f32_2 = try allocator.alloc(f32, 0);

        return .{
            .grayscale = empty_u8,
            .magnitude = empty_f32_1,
            .direction = empty_f32_2,
        };
    }

    const grayscale_img = try rgbToGrayScale(allocator, img);
    errdefer allocator.free(grayscale_img);

    // Validate grayscale image
    if (grayscale_img.len == 0) {
        const empty_f32_1 = try allocator.alloc(f32, 0);
        const empty_f32_2 = try allocator.alloc(f32, 0);

        return .{
            .grayscale = grayscale_img,
            .magnitude = empty_f32_1,
            .direction = empty_f32_2,
        };
    }

    const dog_img = try differenceOfGaussians(allocator, .{
        .data = grayscale_img,
        .width = img.width,
        .height = img.height,
        .channels = 1, // Important fix: grayscale is 1 channel, not `img.channels`
    }, sigma1, sigma2);
    defer allocator.free(dog_img);

    const edge_result = try applySobelFilter(allocator, .{
        .data = dog_img,
        .width = img.width,
        .height = img.height,
        .channels = 1,
    });
    // No defer free as these are returned in EdgeData

    return .{
        .grayscale = grayscale_img,
        .magnitude = edge_result.magnitude,
        .direction = edge_result.direction,
    };
}

const BlockInfo = struct {
    sum_brightness: u64,
    sum_color: [3]u64,
    pixel_count: u64,
    sum_mag: f32,
    sum_dir: f32,
};
pub fn calculateBlockInfo(
    img: Image,
    edge_result: ?EdgeData,
    x: usize,
    y: usize,
    out_w: usize,
    out_h: usize,
    args: CoreParams,
) BlockInfo {
    var info = BlockInfo{ .sum_brightness = 0, .sum_color = .{ 0, 0, 0 }, .pixel_count = 0, .sum_mag = 0, .sum_dir = 0 };

    const block_w = @min(args.block_size, out_w - x);
    const block_h = @min(args.block_size, out_h - y);

    for (0..block_h) |dy| {
        for (0..block_w) |dx| {
            const ix = x + dx;
            const iy = y + dy;
            if (ix >= img.width or iy >= img.height) {
                continue;
            }
            const pixel_index = (iy * img.width + ix) * img.channels;
            if (pixel_index + 2 >= img.width * img.height * img.channels) {
                continue;
            }
            const r = img.data[pixel_index];
            const g = img.data[pixel_index + 1];
            const b = img.data[pixel_index + 2];
            const gray: u64 = @intFromFloat(@as(f32, @floatFromInt(r)) * 0.3 + @as(f32, @floatFromInt(g)) * 0.59 + @as(f32, @floatFromInt(b)) * 0.11);
            info.sum_brightness += gray;
            if (args.color) {
                info.sum_color[0] += r;
                info.sum_color[1] += g;
                info.sum_color[2] += b;
            }
            if (edge_result != null) {
                const edge_index = iy * img.width + ix;
                info.sum_mag += edge_result.?.magnitude[edge_index];
                info.sum_dir += edge_result.?.direction[edge_index];
            }
            info.pixel_count += 1;
        }
    }

    return info;
}

fn calculateAverageColor(block_info: BlockInfo, args: CoreParams) [3]u8 {
    if (args.color) {
        var color = [3]u8{
            @intCast(block_info.sum_color[0] / block_info.pixel_count),
            @intCast(block_info.sum_color[1] / block_info.pixel_count),
            @intCast(block_info.sum_color[2] / block_info.pixel_count),
        };

        if (args.invert_color) {
            color[0] = 255 - color[0];
            color[1] = 255 - color[1];
            color[2] = 255 - color[2];
        }

        return color;
    } else {
        return .{ 255, 255, 255 };
    }
}

fn convertToAscii(
    img: []u8,
    w: usize,
    h: usize,
    x: usize,
    y: usize,
    ascii_char: []const u8,
    color: [3]u8,
    block_size: u8,
    color_enabled: bool,
    args: CoreParams,
) !void {
    const bm = &(try bitmap.getCharSet(ascii_char));
    const block_w = @min(block_size, w - x);
    const block_h = @min(block_size, img.len / (w * 3) - y);

    // Define new colors
    const background_color = if (args.bg_color != null) args.bg_color.? else [3]u8{ 21, 9, 27 }; // Blackcurrant
    const text_color = if (args.fg_color != null) args.fg_color.? else [3]u8{ 211, 106, 111 }; // Indian Red

    var dy: usize = 0;
    while (dy < block_h) : (dy += 1) {
        var dx: usize = 0;
        while (dx < block_w) : (dx += 1) {
            const img_x = x + dx;
            const img_y = y + dy;

            if (img_x < w and img_y < h) {
                const idx = (img_y * w + img_x) * 3;
                const shift: u3 = @intCast(7 - dx);
                const bit: u8 = @as(u8, 1) << shift;
                if ((bm[dy] & bit) != 0) {
                    // Character pixel: use the original color
                    if (color_enabled) {
                        img[idx] = color[0];
                        img[idx + 1] = color[1];
                        img[idx + 2] = color[2];
                    } else {
                        img[idx] = text_color[0];
                        img[idx + 1] = text_color[1];
                        img[idx + 2] = text_color[2];
                    }
                } else {
                    // not a character pixel: set to black
                    if (color_enabled) {
                        img[idx] = 0;
                        img[idx + 1] = 0;
                        img[idx + 2] = 0;
                    } else {
                        img[idx] = background_color[0];
                        img[idx + 1] = background_color[1];
                        img[idx + 2] = background_color[2];
                    }
                }
            }
        }
    }
}

pub fn generateAsciiArt(
    allocator: std.mem.Allocator,
    img: Image,
    edge_result: ?EdgeData,
    args: CoreParams,
) ![]u8 {
    var out_w = (img.width / args.block_size) * args.block_size;
    var out_h = (img.height / args.block_size) * args.block_size;

    out_w = @max(out_w, 1);
    out_h = @max(out_h, 1);

    // Dithering error
    var curr_ditherr = if (args.dither != .None)
        try allocator.alloc(u32, out_w)
    else
        null;
    var next_ditherr = if (args.dither != .None)
        try allocator.alloc(u32, out_w)
    else
        null;
    defer if (curr_ditherr) |buf| allocator.free(buf);
    defer if (next_ditherr) |buf| allocator.free(buf);

    // Initialize error buffers to 0 if they exist
    if (curr_ditherr) |buf| @memset(buf, 0);
    if (next_ditherr) |buf| @memset(buf, 0);

    const ascii_img = try allocator.alloc(u8, out_w * out_h * 3);
    @memset(ascii_img, 0);

    var y: usize = 0;
    while (y < out_h) : (y += args.block_size) {
        if (args.dither != .None) {
            @memset(next_ditherr.?, 0);
        }
        var x: usize = 0;
        while (x < out_w) : (x += args.block_size) {
            var block_info = calculateBlockInfo(img, edge_result, x, y, out_w, out_h, args);

            if (args.dither != .None) {
                const avg_brightness: u8 = @as(u8, @intCast(block_info.sum_brightness / block_info.pixel_count));

                const adjusted_brightness = @as(u32, @intCast(avg_brightness)) +
                    (if (curr_ditherr) |buf| buf[x / args.block_size] else 0);

                const clamped_brightness = @as(u8, @intCast(std.math.clamp(adjusted_brightness, 0, 255)));

                const closest = findClosestBrightness(clamped_brightness, args.ascii_chars, args.ascii_info);

                switch (args.dither.?) {
                    DitherType.FloydSteinberg => floydSteinberg(
                        curr_ditherr.?,
                        next_ditherr.?,
                        @as(u8, @intCast(x)) / args.block_size,
                        @as(u8, @intCast(out_w)) / args.block_size,
                        closest[1],
                    ),
                    DitherType.None => {},
                }

                block_info.sum_brightness = @as(u64, closest[0]) * block_info.pixel_count;
            }

            const ascii_char = selectAsciiChar(block_info, args);
            const avg_color = calculateAverageColor(block_info, args);

            try convertToAscii(ascii_img, out_w, out_h, x, y, ascii_char, avg_color, args.block_size, args.color, args);
        }

        if (curr_ditherr != null and next_ditherr != null) {
            const t = curr_ditherr;
            curr_ditherr = next_ditherr;
            next_ditherr = t;
            if (next_ditherr) |buf| @memset(buf, 0);
        }
    }

    return ascii_img;
}

//-----------------Dithering Functions-----------------------
fn findClosestBrightness(
    desired: u8,
    ascii_chars: []const u8,
    ascii_info: []const AsciiCharInfo,
) struct { u8, u32 } {
    const brightness = @as(u32, @intCast(desired));

    const char_index = (desired * ascii_chars.len) / 256;
    const selected_char = @min(char_index, ascii_info.len - 1);

    const quantized: u32 = @as(u32, @intCast(selected_char)) * (256 / @as(u32, @intCast(ascii_info.len)));

    return .{
        @as(u8, @intCast(quantized)),
        brightness - quantized,
    };
}

/// Original Floyd Steinberg dithering algorithm
/// _ X 7
/// 3 5 1
///
/// (/16)
fn floydSteinberg(
    curr: []u32,
    next: []u32,
    x: u8,
    w: u8,
    quant_error: u32,
) void {
    if (x + 1 < w) {
        curr[x + 1] += (quant_error * 7) >> 4;
        next[x + 1] += (quant_error) >> 4;
    }
    if (x > 0) {
        next[x - 1] += (quant_error * 3) >> 4;
    }
    next[x] += (quant_error * 5) >> 4;
}



================================================
File: src/image.zig
================================================
const std = @import("std");
const stb = @import("stb");
const core = @import("libglyph");
const bitmap = core.bitmap;
const term = @import("libglyphterm");

// -----------------------
// IMAGE PROCESSING FUNCTIONS
// -----------------------

pub fn downloadImage(allocator: std.mem.Allocator, url: []const u8) ![]u8 {
    var client = std.http.Client{ .allocator = allocator };
    defer client.deinit();

    const uri = try std.Uri.parse(url);

    var buf: [4096]u8 = undefined;
    var req = try client.open(.GET, uri, .{ .server_header_buffer = &buf });
    defer req.deinit();

    // Sending HTTP req headers
    try req.send();
    try req.finish();

    // Wait for response
    try req.wait();

    if (req.response.status != .ok) {
        return error.HttpRequestFailed;
    }

    const content_len = req.response.content_length orelse return error.NoContentLength;
    const body = try allocator.alloc(u8, content_len);
    errdefer allocator.free(body);

    const bytes_read = try req.readAll(body);
    if (bytes_read != content_len) {
        return error.IncompleteRead;
    }

    return body;
}

pub fn loadImage(allocator: std.mem.Allocator, path: []const u8) !core.Image {
    const is_url = std.mem.startsWith(u8, path, "http://") or std.mem.startsWith(u8, path, "https://");

    var image_data: []u8 = undefined;
    defer if (is_url) allocator.free(image_data);

    if (is_url) {
        image_data = try downloadImage(allocator, path);
    }

    var w: c_int = undefined;
    var h: c_int = undefined;
    var chan: c_int = undefined;
    const data = if (is_url)
        stb.stbi_load_from_memory(image_data.ptr, @intCast(image_data.len), &w, &h, &chan, 0)
    else
        stb.stbi_load(path.ptr, &w, &h, &chan, 0);

    if (@intFromPtr(data) == 0) {
        std.debug.print("Error loading image: {s}\n", .{path});
        return error.ImageLoadFailed;
    }

    defer stb.stbi_image_free(data);

    // Make sure w, h, and chan are valid to prevent integer overflow
    if (w <= 0 or h <= 0 or chan <= 0) {
        std.debug.print("Invalid image dimensions: w={d}, h={d}, chan={d}\n", .{ w, h, chan });
        return error.InvalidImageDimensions;
    }

    // Validate buffer size to prevent overflow
    const total_pixels = @as(usize, @intCast(w)) * @as(usize, @intCast(h));
    const pixel_size = @as(usize, @intCast(chan));
    const buffer_size = total_pixels * (if (chan == 4) @as(usize, 3) else pixel_size);

    var rgb_data = try allocator.alloc(u8, buffer_size);
    errdefer allocator.free(rgb_data);

    const ext = std.fs.path.extension(path);
    if (std.mem.eql(u8, ext, ".png")) {
        // If image has 4 channels (RGBA), strip the alpha channel
        if (chan == 4) {
            var i: usize = 0;
            var j: usize = 0;
            while (i < total_pixels * 4) : (i += 4) {
                rgb_data[j] = data[i]; // R
                rgb_data[j + 1] = data[i + 1]; // G
                rgb_data[j + 2] = data[i + 2]; // B
                j += 3;
            }

            return core.Image{
                .data = rgb_data,
                .width = @intCast(w),
                .height = @intCast(h),
                .channels = 3,
            };
        }

        @memcpy(rgb_data, data[0 .. total_pixels * @as(usize, @intCast(chan))]);

        return core.Image{
            .data = rgb_data,
            .width = @intCast(w),
            .height = @intCast(h),
            .channels = @intCast(chan),
        };
    }

    @memcpy(rgb_data, data[0 .. total_pixels * @as(usize, @intCast(chan))]);

    return core.Image{
        .data = rgb_data,
        .width = @intCast(w),
        .height = @intCast(h),
        .channels = @intCast(chan),
    };
}

pub fn loadAndScaleImage(allocator: std.mem.Allocator, args: core.CoreParams) !core.Image {
    const original_img = loadImage(allocator, args.input) catch |err| {
        std.debug.print("Error loading image: {}\n", .{err});
        return err;
    };

    if (args.scale != 1.0 and args.scale > 0.0) {
        // Need to free the original image data after scaling
        defer allocator.free(original_img.data);
        return scaleImage(allocator, original_img, args.scale);
    } else {
        return original_img;
    }
}

pub fn scaleImage(allocator: std.mem.Allocator, img: core.Image, scale: f32) !core.Image {
    var img_w = @as(usize, @intFromFloat(@round(@as(f32, @floatFromInt(img.width)) / scale)));
    var img_h = @as(usize, @intFromFloat(@round(@as(f32, @floatFromInt(img.height)) / scale)));

    img_w = @max(img_w, 1);
    img_h = @max(img_h, 1);

    const total_pixels = img_w * img_h;
    const buffer_size = total_pixels * (if (img.channels == 4) @as(usize, 3) else img.channels);

    const scaled_data = try allocator.alloc(u8, buffer_size);
    errdefer allocator.free(scaled_data);

    const scaled_img = stb.stbir_resize_uint8_linear(
        img.data.ptr,
        @intCast(img.width),
        @intCast(img.height),
        0,
        0,
        @intCast(img_w),
        @intCast(img_h),
        0,
        @intCast(img.channels),
    );
    if (scaled_img == null) {
        std.debug.print("Error downscaling image\n", .{});
        return error.ImageScaleFailed;
    }

    defer stb.stbi_image_free(scaled_img);

    @memcpy(scaled_data, scaled_img[0..buffer_size]);

    return core.Image{
        .data = scaled_data,
        .width = img_w,
        .height = img_h,
        .channels = img.channels,
    };
}

pub fn generateAsciiTxt(
    allocator: std.mem.Allocator,
    img: core.Image,
    edge_result: ?core.EdgeData,
    args: core.CoreParams,
) ![]u8 {
    var out_w = (img.width / args.block_size) * args.block_size;
    var out_h = (img.height / args.block_size) * args.block_size;

    out_w = @max(out_w, 1);
    out_h = @max(out_h, 1);

    var ascii_text = std.ArrayList(u8).init(allocator);

    var y: usize = 0;
    while (y < out_h) : (y += args.block_size) {
        var x: usize = 0;
        while (x < out_w) : (x += args.block_size) {
            const block_info = core.calculateBlockInfo(img, edge_result, x, y, out_w, out_h, args);
            const ascii_char = core.selectAsciiChar(block_info, args);
            try ascii_text.appendSlice(ascii_char);
        }
        try ascii_text.append('\n');
    }

    return ascii_text.toOwnedSlice();
}

fn saveOutputTxt(ascii_text: []const u8, args: core.CoreParams) !void {
    const file = try std.fs.cwd().createFile(args.output.?, .{});
    defer file.close();

    try file.writeAll(ascii_text);
}

fn saveOutputImage(ascii_img: []u8, img: core.Image, args: core.CoreParams) !void {
    var out_w = (img.width / args.block_size) * args.block_size;
    var out_h = (img.height / args.block_size) * args.block_size;

    out_w = @max(out_w, 1);
    out_h = @max(out_h, 1);

    const save_result = stb.stbi_write_png(
        @ptrCast(args.output.?.ptr),
        @intCast(out_w),
        @intCast(out_h),
        @intCast(img.channels),
        @ptrCast(ascii_img.ptr),
        @intCast(out_w * 3),
    );
    if (save_result == 0) {
        std.debug.print("Error writing output image\n", .{});
        return error.ImageWriteFailed;
    }
}

pub fn processImage(allocator: std.mem.Allocator, args: core.CoreParams) !void {
    const original_img = try loadAndScaleImage(allocator, args);

    // Safety check for image dimensions
    if (original_img.width == 0 or original_img.height == 0) {
        std.debug.print("Error: Invalid image dimensions\n", .{});
        return error.InvalidImageDimensions;
    }

    const expected_size = original_img.width * original_img.height * original_img.channels;
    const adjusted_data = if (args.auto_adjust)
        try core.autoBrightnessContrast(allocator, original_img, 1.0)
    else
        try allocator.dupe(u8, original_img.data[0..expected_size]);

    const adjusted_img = core.Image{
        .data = adjusted_data,
        .width = original_img.width,
        .height = original_img.height,
        .channels = original_img.channels,
    };

    const edge_result = try core.detectEdges(allocator, adjusted_img, args.detect_edges, args.sigma1, args.sigma2);

    switch (args.output_type) {
        core.OutputType.Image => {
            const ascii_img = try core.generateAsciiArt(
                allocator,
                adjusted_img,
                edge_result,
                args,
            );
            try saveOutputImage(ascii_img, adjusted_img, args);
        },
        core.OutputType.Stdout => {
            var t = try term.init(allocator, args.ascii_chars);

            var new_w: usize = 0;
            var new_h: usize = 0;
            if (args.stretched) {
                new_w = t.size.w - 2;
                new_h = t.size.h - 4;
            } else {
                const rw = adjusted_img.width / (t.size.w - 2);
                const rh = adjusted_img.height / (t.size.h - 4);
                if (rw > rh) {
                    new_h = adjusted_img.height / (rw * 2);
                    new_w = t.size.w - 2;
                } else {
                    new_h = (t.size.h - 4) / 2;
                    new_w = adjusted_img.width / rh;
                }
            }
            new_w = @max(new_w, 1);
            new_h = @max(new_h, 1);

            const img = try core.resizeImage(allocator, adjusted_img, new_w, new_h);

            t.stats = .{
                .original_w = adjusted_img.width,
                .original_h = adjusted_img.height,
                .new_w = img.width,
                .new_h = img.height,
            };

            const img_len = img.height * img.width * img.channels;

            try t.enableAsciiMode();
            const params = term.RenderParams{
                .img = img.data[0..img_len],
                .width = img.width,
                .height = img.height,
                .channels = img.channels,
                .color = args.color,
                .invert = args.invert_color,
            };
            try t.renderAsciiArt(params);

            // Wait for user input before exiting
            _ = try t.stdin.readByte();
            try t.disableAsciiMode();
        },
        core.OutputType.Text => {
            // 1 : og
            // dr : grid
            var img: core.Image = adjusted_img;
            var h = adjusted_img.height;
            const w = adjusted_img.width;
            if (adjusted_img.height >= 2) {
                h = adjusted_img.height / 2;
                img = try core.resizeImage(allocator, adjusted_img, w, h);
            }
            const ascii_txt = try generateAsciiTxt(
                allocator,
                img,
                edge_result,
                args,
            );
            try saveOutputTxt(ascii_txt, args);
        },
        else => {},
    }
}

// TESTS



================================================
File: src/main.zig
================================================
const std = @import("std");
const builtin = @import("builtin");
const clap = @import("clap");
const core = @import("libglyph");
const image = @import("libglyphimg");
const video = @import("libglyphav");
const term = @import("libglyphterm");
const bitmap = core.bitmap;
const build_options = @import("build_options");
const version = build_options.version;
const version_string = std.fmt.comptimePrint("{d}.{d}.{d}", .{ version.major, version.minor, version.patch });

const default_block = " .:coPO?@█";
const default_ascii = " .:-=+*%@#";
const full_characters = " .-:=+iltIcsv1x%7aejorzfnuCJT3*69LYpqy25SbdgFGOVXkPhmw48AQDEHKUZR@B#NW0M";

fn parseArgs(allocator: std.mem.Allocator) !core.CoreParams {
    const params = comptime clap.parseParamsComptime(
        \\-h, --help                     Print this help message and exit
        \\-v, --version                  Prints the version and exit
        \\-i, --input <str>              Input media file (img, video)
        \\-o, --output <str>             Output file (img, video, txt)
        \\-c, --color                    Use color ASCII characters
        \\-n, --invert_color             Inverts the color values
        \\-a, --auto_adjust              Auto adjusts the brightness and contrast of input media
        \\-s, --scale <f32>              Scale factor (default: 1.0)
        \\    --symbols <str>            Character set to use: "ascii" or "block" (default: ascii)
        \\-e, --detect_edges             Detect edges
        \\    --sigma1 <f32>             Sigma 1 for DoG filter (default: 0.5)
        \\    --sigma2 <f32>             Sigma 2 for DoG filter (default: 1.0)
        \\-b, --brightness_boost <f32>   Brightness boost (default: 1.0)
        \\    --full_characters          Uses full spectrum of characters in image.
        \\    --ascii_chars <str>        Use what characters you want to use in the image. (default: " .:-=+*%#@")
        \\    --disable_sort             Prevents sorting of the ascii_chars by size.
        \\    --block_size <u8>          Set the size of the blocks. (default: 8)
        \\    --threshold_disabled       Disables the threshold.
        \\    --codec <str>              Encoder Codec like "libx264" or "hevc_videotoolbox" (optional)
        \\    --keep_audio               Keeps the audio if input is a video
        \\    --stretched                Resizes media to fit terminal window
        \\-f, --frame_rate <f32>         Target frame rate for video output (default: matches input fps)
        \\-d, --dither <str>             Dithering, supported values: "floydstein" (default: "floydstein")
        \\    --fg <str>                 Enter a hex value like "#ffffff" for the foreground color (default: "#d36a6f")
        \\    --bg <str>                 Enter a hex value like "#000000" for the background color (default: "#15091b")
        \\<str>...
    );

    var diag = clap.Diagnostic{};
    var res = clap.parse(clap.Help, &params, clap.parsers.default, .{
        .allocator = allocator,
        .diagnostic = &diag,
    }) catch |err| {
        diag.report(std.io.getStdErr().writer(), err) catch {};
        return err;
    };
    defer res.deinit();

    if (res.args.help != 0) {
        try clap.help(std.io.getStdOut().writer(), clap.Help, &params, .{});
        std.process.exit(0);
    }

    if (res.args.version != 0) {
        try std.io.getStdOut().writer().writeAll(version_string ++ "\n");
        std.process.exit(0);
    }

    if (res.args.input == null) {
        std.debug.print("Error: input file must be specified.\n", .{});
        std.process.exit(1);
    }

    const output_type = if (res.args.output) |op| blk: {
        const ext = std.fs.path.extension(op);
        if (std.mem.eql(u8, ext, ".txt")) {
            break :blk core.OutputType.Text;
        } else if (video.isVideoFile(op)) {
            break :blk core.OutputType.Video;
        } else {
            break :blk core.OutputType.Image;
        }
    } else core.OutputType.Stdout;

    var ffmpeg_options = std.StringHashMap([]const u8).init(allocator);
    errdefer ffmpeg_options.deinit();
    var pos: usize = 0;
    while (pos < res.positionals[0].len) : (pos += 2) {
        if (output_type != core.OutputType.Video) {
            std.debug.print("Warning: You have passed options not meant for this input/output type, they will be ignored.\n", .{});
            break;
        }
        const positional = res.positionals[0][pos];
        if (std.mem.startsWith(u8, positional, "-")) {
            const key = positional[1..];
            const val = if (pos + 1 < res.positionals[0].len) res.positionals[0][pos + 1] else return error.ValueNotFound;
            try ffmpeg_options.put(key, val);
        }
    }

    const ascii_chars = blk: {
        if (res.args.ascii_chars) |custom_chars| {
            if (res.args.disable_sort != 0) {
                break :blk custom_chars;
            } else {
                break :blk sortCharsBySize(allocator, custom_chars) catch getDefaultChars(res.args.symbols);
            }
        } else if (res.args.full_characters != 0) {
            break :blk full_characters;
        } else {
            break :blk getDefaultChars(res.args.symbols);
        }
    };

    const ascii_info = try core.initAsciiChars(allocator, ascii_chars);

    const dither = blk: {
        if (res.args.dither != null) {
            if (std.mem.eql(u8, res.args.dither.?, "floydstein")) {
                break :blk core.DitherType.FloydSteinberg;
            } else {
                break :blk core.DitherType.None;
            }
        } else {
            break :blk core.DitherType.None;
        }
    };

    const fg_color = blk: {
        if (res.args.fg != null) {
            break :blk try hexToRgb(res.args.fg.?);
        } else break :blk null;
    };

    const bg_color = blk: {
        if (res.args.bg != null) {
            break :blk try hexToRgb(res.args.bg.?);
        } else break :blk null;
    };

    return core.CoreParams{
        .input = res.args.input.?,
        .output_type = output_type,
        .output = res.args.output,
        .color = res.args.color != 0,
        .invert_color = res.args.invert_color != 0,
        .auto_adjust = res.args.auto_adjust != 0,
        .scale = res.args.scale orelse 1.0,
        .detect_edges = res.args.detect_edges != 0,
        .sigma1 = res.args.sigma1 orelse 0.5,
        .sigma2 = res.args.sigma2 orelse 1.0,
        .brightness_boost = res.args.brightness_boost orelse 1.0,
        .ascii_chars = ascii_chars,
        .ascii_info = ascii_info,
        .block_size = res.args.block_size orelse 8,
        .threshold_disabled = res.args.threshold_disabled != 0,
        .codec = res.args.codec,
        .keep_audio = res.args.keep_audio != 0,
        .ffmpeg_options = ffmpeg_options,
        .frame_rate = res.args.frame_rate,
        .stretched = res.args.stretched != 0,
        .dither = dither,
        .fg_color = fg_color,
        .bg_color = bg_color,
    };
}

fn getDefaultChars(symbols: ?[]const u8) []const u8 {
    const symbol_type = if (symbols) |s|
        if (std.mem.eql(u8, s, "ascii")) core.SymbolType.Ascii else core.SymbolType.Block
    else
        core.SymbolType.Ascii;
    return switch (symbol_type) {
        .Ascii => default_ascii,
        .Block => default_block,
    };
}

fn sortCharsBySize(allocator: std.mem.Allocator, input: []const u8) ![]const u8 {
    const CharInfo = struct {
        char: []const u8,
        size: usize,
    };

    var char_infos = std.ArrayList(CharInfo).init(allocator);
    defer char_infos.deinit();

    var it = std.unicode.Utf8Iterator{ .bytes = input, .i = 0 };
    while (it.nextCodepoint()) |codepoint| {
        const len = std.unicode.utf8CodepointSequenceLength(codepoint) catch continue;
        const char_start = it.i - len;
        const char = input[char_start..it.i];

        const bm = bitmap.getCharSet(char) catch continue;
        var size: usize = 0;

        for (bm) |row| {
            size += @popCount(row);
        }

        if (size == 0 and !std.mem.eql(u8, char, " ")) continue; // Skip zero-size characters except space

        try char_infos.append(.{ .char = char, .size = size });
    }

    // Sort characters by size
    std.mem.sort(CharInfo, char_infos.items, {}, struct {
        fn lessThan(_: void, a: CharInfo, b: CharInfo) bool {
            return a.size < b.size;
        }
    }.lessThan);

    // Create the sorted string
    var result = std.ArrayList(u8).init(allocator);
    for (char_infos.items) |char_info| {
        try result.appendSlice(char_info.char);
    }

    return result.toOwnedSlice();
}

fn hexToRgb(hex: []const u8) ![3]u8 {
    if (hex[0] != '#') return error.InvalidHexString;
    if (hex.len != 7) return error.InvalidHexString;
    const r = try std.fmt.parseInt(u8, hex[1..3], 16);
    const g = try std.fmt.parseInt(u8, hex[3..5], 16);
    const b = try std.fmt.parseInt(u8, hex[5..7], 16);
    return .{ r, g, b };
}

// -----------------------
// MAIN ENTRYPOINT AND HELPER FUNCTIONS
// -----------------------

pub fn main() !void {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    const allocator = gpa.allocator();
    var arena = std.heap.ArenaAllocator.init(allocator);
    defer arena.deinit();

    const args = try parseArgs(allocator);

    if (video.isVideoFile(args.input)) {
        try video.processVideo(allocator, args);
    } else {
        try image.processImage(allocator, args);
    }
}



================================================
File: src/mime.zig
================================================
const std = @import("std");
/// Author: andrewrk
/// Source: https://github.com/andrewrk/mime/blob/2.0.0/mime.zig
/// The integer values backing these enum tags are not protected by the
/// semantic version of this package but the backing integer type is.
/// The tags are guaranteed to be sorted by name.
pub const Type = enum(u16) {
    @"image/bmp",
    @"image/gif",
    @"image/jpeg",
    @"image/png",
    @"image/svg+xml",
    @"image/tiff",
    @"image/vnd.microsoft.icon",
    @"image/webp",
    @"video/3gpp",
    @"video/3gpp2",
    @"video/mp2t",
    @"video/mp4",
    @"video/mpeg",
    @"video/ogg",
    @"video/quicktime",
    @"video/webm",
    @"video/x-msvideo",
};

/// Maps file extension to mime type.
pub const extension_map = std.StaticStringMap(Type).initComptime(.{
    .{ ".bmp", .@"image/bmp" },
    .{ ".gif", .@"image/gif" },
    .{ ".ico", .@"image/vnd.microsoft.icon" },
    .{ ".jpg", .@"image/jpeg" },
    .{ ".jpeg", .@"image/jpeg" },
    .{ ".png", .@"image/png" },
    .{ ".svg", .@"image/svg+xml" },
    .{ ".tiff", .@"image/tiff" },
    .{ ".webp", .@"image/webp" },
    .{ ".avi", .@"video/x-msvideo" },
    .{ ".mov", .@"video/quicktime" },
    .{ ".mp4", .@"video/mp4" },
    .{ ".mpeg", .@"video/mpeg" },
    .{ ".ogv", .@"video/ogg" },
    .{ ".ts", .@"video/mp2t" },
    .{ ".webm", .@"video/webm" },
    .{ ".3gp", .@"video/3gpp" },
    .{ ".3g2", .@"video/3gpp2" },
});



================================================
File: src/term.zig
================================================
const std = @import("std");
const builtin = @import("builtin");
const core = @import("libglyph");

pub const TermSize = struct {
    h: usize,
    w: usize,
};

pub const Stats = struct {
    original_w: usize,
    original_h: usize,
    new_w: usize,
    new_h: usize,
    fps: ?f32 = null,
    frame_delay: ?i64 = null,
    avg_frame_time: ?u128 = null,
    frame_count: ?u64 = null,
    total_time: ?u128 = 0,
};

const MAX_COLOR = 256;
const LAST_COLOR = MAX_COLOR - 1;

// ANSI escape codes
const ESC = "\x1B";
const CSI = ESC ++ "[";

const SHOW_CURSOR = CSI ++ "?25h";
const HIDE_CURSOR = CSI ++ "?25l";
const HOME_CURSOR = CSI ++ "1;1H";
const SAVE_CURSOR = ESC ++ "7";
const LOAD_CURSOR = ESC ++ "8";

const CLEAR_SCREEN = CSI ++ "2J";
const ALT_BUF_ENABLE = CSI ++ "?1049h";
const ALT_BUF_DISABLE = CSI ++ "?1049l";

const CLEAR_TO_EOL = CSI ++ "0K";

const RESET_COLOR = CSI ++ "0m";
const SET_FG_COLOR = "38;5";
const SET_BG_COLOR = "48;5";

const WHITE_FG = CSI ++ SET_FG_COLOR ++ ";15m";
const BLACK_BG = CSI ++ SET_BG_COLOR ++ ";0m";
const BLACK_FG = CSI ++ SET_FG_COLOR ++ ";0m";
const OG_COLOR = BLACK_BG ++ WHITE_FG;

const ASCII_TERM_ON = ALT_BUF_ENABLE ++ HIDE_CURSOR ++ HOME_CURSOR ++ CLEAR_SCREEN;
const ASCII_TERM_OFF = ALT_BUF_DISABLE ++ SHOW_CURSOR ++ "\n";

// RGB ANSI escape codes
const RGB_FG = CSI ++ "38;2;";
const RGB_BG = CSI ++ "48;2;";

const TIOCGWINSZ = std.c.T.IOCGWINSZ;

allocator: std.mem.Allocator,
stdout: std.fs.File.Writer,
stdin: std.fs.File.Reader,
size: TermSize,
ascii_chars: []const u8,
ascii_info: []core.AsciiCharInfo,
stats: Stats,
buf: []u8,
buf_index: usize,
buf_len: usize,
init_frame: []u8,
// fg: [MAX_COLOR][]u8,
// bg: [MAX_COLOR][]u8,

const Self = @This();

pub fn init(allocator: std.mem.Allocator, ascii_chars: []const u8) !Self {
    const stdout = std.io.getStdOut().writer();
    const stdin = std.io.getStdIn().reader();
    const size = try getTermSize(std.io.getStdOut().handle);

    const ascii_info = try core.initAsciiChars(allocator, ascii_chars);

    const char_size = ascii_chars.len;
    const color_size = RGB_FG.len + 12;
    const ascii_size = char_size + color_size;
    const screen_size: u64 = @intCast(ascii_size * size.w * size.h);
    const overflow_size: u64 = char_size * 100;
    const buf_size = screen_size + overflow_size;
    const buf = try allocator.alloc(u8, buf_size);

    const init_frame = std.fmt.allocPrint(
        allocator,
        "{s}{s}{s}",
        .{ HOME_CURSOR, BLACK_BG, BLACK_FG },
    ) catch unreachable;

    const self = Self{
        .allocator = allocator,
        .stdout = stdout,
        .stdin = stdin,
        .size = size,
        .ascii_chars = ascii_chars,
        .ascii_info = ascii_info,
        .stats = undefined,
        .buf = buf,
        .buf_index = 0,
        .buf_len = 0,
        .init_frame = init_frame,
        // .fg = undefined,
        // .bg = undefined,
    };

    // try self.initColor();
    return self;
}

pub fn deinit(self: *Self) void {
    self.allocator.free(self.buf);
    self.allocator.free(self.init_frame);
    self.allocator.free(self.ascii_info);
    // for (0..MAX_COLOR) |i| {
    //     self.allocator.free(self.fg[i]);
    //     self.allocator.free(self.bg[i]);
    // }
}

pub fn enableAsciiMode(self: *Self) !void {
    try self.stdout.writeAll(ASCII_TERM_ON);
}

pub fn disableAsciiMode(self: *Self) !void {
    try self.stdout.writeAll(ASCII_TERM_OFF);
}

pub fn clear(self: *Self) !void {
    try self.stdout.writeAll(CLEAR_SCREEN);
    try self.stdout.writeAll(HOME_CURSOR);
}

fn resetBuffer(self: *Self) void {
    @memset(self.buf, 0);
    self.buf_index = 0;
    self.buf_len = 0;
}

fn writeToBuffer(self: *Self, s: []const u8) void {
    @memcpy(self.buf[self.buf_index..][0..s.len], s);
    self.buf_index += s.len;
    self.buf_len += s.len;
}

pub const RenderParams = struct {
    img: []const u8,
    width: usize,
    height: usize,
    channels: usize,
    color: bool,
    invert: bool,
};
pub fn renderAsciiArt(
    self: *Self,
    params: RenderParams,
) !void {
    const v_padding: usize = (self.size.h - params.height - 1) / 2; // Account for top and bottom borders

    var i: usize = 0;
    self.writeToBuffer(self.init_frame);
    if (!params.color) {
        self.writeToBuffer(WHITE_FG);
    }
    while (i < v_padding) : (i += 1) {
        self.writeToBuffer("\n");
    }

    // Print top border
    // for (0..h_padding) |_| self.writeToBuffer(" ");
    // self.writeToBuffer("┌");
    // for (0..width) |_| self.writeToBuffer("-");
    // self.writeToBuffer("┐\n");

    var timer = try std.time.Timer.start();
    var y: usize = 0;
    while (y < params.height) : (y += 1) {
        // for (0..h_padding) |_| self.writeToBuffer(" ");
        // self.writeToBuffer("│");

        var x: usize = 0;
        while (x < params.width) : (x += 1) {
            const idx = (y * params.width + x) * params.channels;

            const ascii_char = getAsciiChar(self, params, idx);

            if (params.color) {
                var r = params.img[idx];
                var g = params.img[idx + 1];
                var b = params.img[idx + 2];
                if (params.invert) {
                    r = 255 - r;
                    g = 255 - g;
                    b = 255 - b;
                }
                var color_code_buf: [32]u8 = undefined;
                const color_code = std.fmt.bufPrint(
                    &color_code_buf,
                    RGB_FG ++ "{d};{d};{d}m{s}" ++ RESET_COLOR,
                    .{ r, g, b, ascii_char },
                ) catch unreachable;
                self.writeToBuffer(color_code);
            } else {
                self.writeToBuffer(ascii_char);
            }
        }

        // self.writeToBuffer("│\n");
        self.writeToBuffer("\n");
    }

    const elapsed = timer.read();
    self.stats.total_time.? += @as(u128, @intCast(elapsed));

    try self.flushBuffer();
    // Print bottom border
    // for (0..h_padding) |_| self.writeToBuffer(" ");
    // self.writeToBuffer("└");
    // for (0..width) |_| self.writeToBuffer("-");
    // self.writeToBuffer("┘\n");

    // Print bottom padding
    i = 0;
    while (i < v_padding) : (i += 1) {
        self.writeToBuffer("\n");
    }

    try self.flushBuffer();
    try self.printStats();
    self.resetBuffer();
}

fn getAsciiChar(
    self: *Self,
    params: RenderParams,
    idx: usize,
) []const u8 {
    const brightness = if (params.invert) 255 - params.img[idx] else params.img[idx];
    const ascii_idx = (brightness * self.ascii_info.len) / 256;
    const selected_char = self.ascii_info[@min(ascii_idx, self.ascii_info.len - 1)];
    return self.ascii_chars[selected_char.start .. selected_char.start + selected_char.len];
}

fn flushBuffer(self: *Self) !void {
    _ = try self.stdout.write(self.buf[0 .. self.buf_len - 1]);
}

pub fn printStats(self: *Self) !void {
    const original_aspect_ratio = @as(f32, @floatFromInt(self.stats.original_w)) / @as(f32, @floatFromInt(self.stats.original_h));
    const new_aspect_ratio = @as(f32, @floatFromInt(self.stats.new_w)) / @as(f32, @floatFromInt(self.stats.new_h));

    const stats_str = if (self.stats.fps) |fps| blk: {
        const s = try std.fmt.allocPrint(self.allocator, "\nOriginal: {}x{} (AR: {d:.2}) | New: {}x{} (AR: {d:.2}) | FPS: {d:.2} | Frame Delay: {d}", .{
            self.stats.original_w,
            self.stats.original_h,
            original_aspect_ratio,
            self.stats.new_w,
            self.stats.new_h,
            new_aspect_ratio,
            fps,
            self.stats.frame_delay.?,
        });
        break :blk s;
    } else try std.fmt.allocPrint(self.allocator, "\nOriginal: {}x{} (AR: {d:.2}) | New: {}x{} (AR: {d:.2}) | Term: {}x{} |", .{
        self.stats.original_w,
        self.stats.original_h,
        original_aspect_ratio,
        self.stats.new_w,
        self.stats.new_h,
        new_aspect_ratio,
        self.size.w,
        self.size.h,
    });
    defer self.allocator.free(stats_str);

    self.writeToBuffer(stats_str);
    try self.flushBuffer();
}

pub fn getTermSize(tty: std.posix.fd_t) !TermSize {
    switch (builtin.os.tag) {
        .windows => {
            const win32 = std.os.windows.kernel32;
            var info: std.os.windows.CONSOLE_SCREEN_BUFFER_INFO = undefined;
            if (win32.GetConsoleScreenBufferInfo(tty, &info) == 0) switch (win32.GetLastError()) {
                else => |e| return std.os.windows.unexpectedError(e),
            };
            return .{
                .h = @intCast(info.srWindow.Bottom - info.srWindow.Top + 1),
                .w = @intCast(info.srWindow.Right - info.srWindow.Left + 1),
            };
        },
        else => {
            var winsize = std.c.winsize{
                .col = 0,
                .row = 0,
                .xpixel = 0,
                .ypixel = 0,
            };
            const ret_val = std.c.ioctl(tty, TIOCGWINSZ, @intFromPtr(&winsize));
            const err = std.posix.errno(ret_val);

            if (ret_val >= 0) {
                return .{
                    .h = winsize.row,
                    .w = winsize.col,
                };
            } else {
                return std.posix.unexpectedErrno(err);
            }
        },
    }
}



================================================
File: src/tests.zig
================================================
const std = @import("std");
pub const core = @import("libglyph");
pub const image = @import("libglyphimg");
pub const term = @import("libglyphterm");
pub const video = @import("libglyphav");
const stb = core.stb;

test "loadImage - png" {
    const allocator = std.testing.allocator;
    const test_path = "test_img.png";

    const img = try image.loadImage(allocator, test_path);
    defer allocator.free(img.data);

    try std.testing.expect(img.width > 0);
    try std.testing.expect(img.height > 0);
    try std.testing.expect(img.channels == 3 or img.channels == 4);
}

test "scaleImage - downscaling" {
    const allocator = std.testing.allocator;
    const test_data = try allocator.alloc(u8, 100 * 100 * 3);
    defer allocator.free(test_data);
    @memset(test_data, 128); // fill with mid-gray

    const orig_img = core.Image{
        .data = test_data,
        .width = 100,
        .height = 100,
        .channels = 3,
    };

    const scaled = try image.scaleImage(allocator, orig_img, 2.0);
    defer allocator.free(scaled.data);

    try std.testing.expectEqual(@as(usize, 50), scaled.width);
    try std.testing.expectEqual(@as(usize, 50), scaled.height);
}

test "scaleImage - upscaling" {
    const allocator = std.testing.allocator;
    const test_data = try allocator.alloc(u8, 100 * 100 * 3);
    defer allocator.free(test_data);
    @memset(test_data, 128); // fill with mid-gray

    const orig_img = core.Image{
        .data = test_data,
        .width = 100,
        .height = 100,
        .channels = 3,
    };

    const scaled = try image.scaleImage(allocator, orig_img, 0.5);
    defer allocator.free(scaled.data);

    try std.testing.expectEqual(@as(usize, 200), scaled.width);
    try std.testing.expectEqual(@as(usize, 200), scaled.height);
}

test "text" {
    const allocator = std.testing.allocator;
    var test_data = try allocator.alloc(u8, 16 * 16 * 3);
    defer allocator.free(test_data);

    // Create gradient
    for (0..16) |y| {
        for (0..16) |x| {
            const idx = (y * 16 + x) * 3;
            test_data[idx] = @intCast(x * 16); // R
            test_data[idx + 1] = @intCast(y * 16); // G
            test_data[idx + 2] = 128; // B
        }
    }

    const img = core.Image{
        .data = test_data,
        .width = 16,
        .height = 16,
        .channels = 3,
    };

    const ascii_info = try core.initAsciiChars(allocator, " .:-=+*#@");
    defer allocator.free(ascii_info);

    const args = core.CoreParams{
        .input = "test_img.png",
        .output = null,
        .color = false,
        .invert_color = false,
        .auto_adjust = false,
        .scale = 1.0,
        .detect_edges = false,
        .sigma1 = 0.5,
        .sigma2 = 1.0,
        .brightness_boost = 1.0,
        .ascii_chars = " .:-=+*#@",
        .ascii_info = ascii_info,
        .stretched = false,
        .block_size = 8,
        .output_type = .Image,
        .frame_rate = null,
        .ffmpeg_options = std.StringHashMap([]const u8).init(allocator),
        .keep_audio = false,
        .codec = null,
        .dither = .None,
        .bg_color = null,
        .fg_color = null,
        .threshold_disabled = false,
    };

    const ascii_txt = try image.generateAsciiTxt(allocator, img, null, args);
    defer allocator.free(ascii_txt);

    try std.testing.expect(ascii_txt.len > 0);
    try std.testing.expect(std.mem.indexOf(u8, ascii_txt, "\n") != null);
}



================================================
File: src/video.zig
================================================
const std = @import("std");
const builtin = @import("builtin");
const core = @import("libglyph");
const term = @import("libglyphterm");
const mime = @import("mime.zig");
const av = @import("av");
const stb = @import("stb");
const Thread = std.Thread;
const Mutex = Thread.Mutex;
const Condition = Thread.Condition;

pub fn FrameBuffer(comptime T: type) type {
    return struct {
        const Self = @This();
        frames: std.ArrayList(T),
        w: usize = 0,
        h: usize = 0,
        channels: usize = 3,
        mutex: Mutex,
        cond: Condition,
        max_size: usize,
        is_finished: bool,
        allocator: std.mem.Allocator,
        ready: bool,

        pub fn init(allocator: std.mem.Allocator, max_size: usize) Self {
            return .{
                .frames = std.ArrayList(T).init(allocator),
                .mutex = Mutex{},
                .cond = Condition{},
                .max_size = max_size,
                .is_finished = false,
                .allocator = allocator,
                .ready = false,
            };
        }

        pub fn deinit(self: *Self) void {
            self.frames.deinit();
        }

        pub fn push(self: *Self, frame: T) !void {
            self.mutex.lock();
            defer self.mutex.unlock();

            while (self.frames.items.len >= self.max_size) {
                self.cond.wait(&self.mutex);
            }

            try self.frames.append(frame);
            self.cond.signal();
        }

        pub fn pop(self: *Self) ?T {
            self.mutex.lock();
            defer self.mutex.unlock();

            while (self.frames.items.len == 0 and !self.is_finished) {
                self.cond.wait(&self.mutex);
            }

            if (self.frames.items.len == 0) {
                return null;
            }

            const frame = self.frames.orderedRemove(0);
            self.cond.signal();
            return frame;
        }

        pub fn setFinished(self: *Self) void {
            self.mutex.lock();
            defer self.mutex.unlock();
            self.is_finished = true;
            self.cond.broadcast();
        }

        pub fn setReady(self: *Self) void {
            self.mutex.lock();
            defer self.mutex.unlock();
            self.ready = true;
            self.cond.broadcast();
        }

        pub fn waitUntilReady(self: *Self) void {
            self.mutex.lock();
            defer self.mutex.unlock();
            while (!self.ready) {
                self.cond.wait(&self.mutex);
            }
        }
    };
}

// -----------------------
// VIDEO PROCESSING FUNCTIONS
// -----------------------

pub fn isVideoFile(file_path: []const u8) bool {
    const extension = std.fs.path.extension(file_path);
    if (mime.extension_map.get(extension)) |mime_type| {
        return switch (mime_type) {
            .@"video/3gpp",
            .@"video/3gpp2",
            .@"video/mp2t",
            .@"video/mp4",
            .@"video/mpeg",
            .@"video/ogg",
            .@"video/quicktime",
            .@"video/webm",
            .@"video/x-msvideo",
            => true,
            else => false,
        };
    }
    return false;
}

fn openInputVideo(path: []const u8) !*av.AVFormatContext {
    var fmt_ctx: ?*av.AVFormatContext = null;
    if (av.avformat_open_input(
        &fmt_ctx,
        path.ptr,
        null,
        null,
    ) < 0) {
        return error.FailedToOpenInputVideo;
    }
    if (av.avformat_find_stream_info(fmt_ctx, null) < 0) {
        return error.FailedToFindStreamInfo;
    }
    return fmt_ctx.?;
}

const AVStream = struct {
    stream: *av.AVStream,
    index: c_int,
};
fn openVideoStream(fmt_ctx: *av.AVFormatContext) !AVStream {
    const index = av.av_find_best_stream(
        fmt_ctx,
        av.AVMEDIA_TYPE_VIDEO,
        -1,
        -1,
        null,
        0,
    );
    if (index < 0) {
        return error.VideoStreamNotFound;
    }

    return .{
        .stream = fmt_ctx.streams[@intCast(index)],
        .index = index,
    };
}

fn createDecoder(stream: *av.AVStream) !*av.AVCodecContext {
    const decoder = av.avcodec_find_decoder(
        stream.codecpar.*.codec_id,
    ) orelse {
        return error.DecoderNotFound;
    };
    const codex_ctx = av.avcodec_alloc_context3(decoder);
    if (codex_ctx == null) {
        return error.FailedToAllocCodecCtx;
    }
    if (av.avcodec_parameters_to_context(
        codex_ctx,
        stream.codecpar,
    ) < 0) {
        return error.FailedToSetCodecParams;
    }
    if (av.avcodec_open2(
        codex_ctx,
        decoder,
        null,
    ) < 0) {
        return error.FailedToOpenEncoder;
    }

    return codex_ctx;
}

fn setEncoderOption(enc_ctx: *av.AVCodecContext, key: []const u8, value: []const u8) bool {
    var opt: ?*const av.AVOption = null;

    // Try to find the option in AVCodecContext
    opt = av.av_opt_find(@ptrCast(enc_ctx), key.ptr, null, 0, 0);
    if (opt != null) {
        if (av.av_opt_set(enc_ctx, key.ptr, value.ptr, 0) >= 0) {
            return true;
        }
    }

    // If not found or setting failed, try in priv_data
    if (enc_ctx.*.priv_data != null) {
        opt = av.av_opt_find(enc_ctx.*.priv_data, key.ptr, null, 0, 0);
        if (opt != null) {
            if (av.av_opt_set(enc_ctx.*.priv_data, key.ptr, value.ptr, 0) >= 0) {
                return true;
            }
        }
    }

    return false;
}

fn createEncoder(
    codec_ctx: *av.AVCodecContext,
    stream: *av.AVStream,
    args: core.CoreParams,
) !*av.AVCodecContext {
    const encoder = if (args.codec) |codec| av.avcodec_find_encoder_by_name(codec.ptr) else av.avcodec_find_encoder_by_name("h264_nvenc") orelse
        av.avcodec_find_encoder_by_name("hevc_amf") orelse
        av.avcodec_find_encoder_by_name("hevc_qsv") orelse
        av.avcodec_find_encoder_by_name("hevc_videotoolbox") orelse
        av.avcodec_find_encoder_by_name("libx265") orelse
        av.avcodec_find_encoder_by_name("h264_amf") orelse
        av.avcodec_find_encoder_by_name("h264_qsv") orelse
        av.avcodec_find_encoder_by_name("libx264") orelse
        return error.EncoderNotFound;

    const enc_ctx = av.avcodec_alloc_context3(encoder);
    if (enc_ctx == null) {
        return error.FailedToAllocCodecCtx;
    }

    // Setting up encoding context
    enc_ctx.*.width = codec_ctx.width;
    enc_ctx.*.height = codec_ctx.height;
    enc_ctx.*.pix_fmt = av.AV_PIX_FMT_YUV420P;
    // enc_ctx.*.pix_fmt = encoder.*.pix_fmts[0];
    enc_ctx.*.time_base = stream.time_base;
    enc_ctx.*.framerate = .{
        .num = codec_ctx.framerate.num,
        .den = 1,
    };
    enc_ctx.*.gop_size = 10;
    enc_ctx.*.max_b_frames = 1;
    enc_ctx.*.flags |= av.AV_CODEC_FLAG_GLOBAL_HEADER;

    // Ensure the stride is aligned to 32 bytes
    const stride = (enc_ctx.*.width + 31) & ~@as(c_int, 31);
    _ = av.av_opt_set(enc_ctx, "stride", stride, 0);

    var it = args.ffmpeg_options.iterator();
    while (it.next()) |entry| {
        const k = entry.key_ptr.*;
        const v = entry.value_ptr.*;
        if (!setEncoderOption(enc_ctx, k, v)) {
            std.debug.print("Warning: Failed to set FFmpeg option: {s}={s}\n", .{ k, v });
        }
    }

    if (av.avcodec_open2(enc_ctx, encoder, null) < 0) {
        return error.FailedToOpenEncoder;
    }

    return enc_ctx;
}

const OutputContext = struct {
    ctx: *av.AVFormatContext,
    video_stream: *av.AVStream,
    audio_stream: ?*av.AVStream,
};
fn createOutputCtx(output_path: []const u8, enc_ctx: *av.AVCodecContext, audio_stream: ?*av.AVStream) !OutputContext {
    var fmt_ctx: ?*av.AVFormatContext = null;
    if (av.avformat_alloc_output_context2(&fmt_ctx, null, null, output_path.ptr) < 0) {
        return error.FailedToCreateOutputCtx;
    }

    const video_stream = av.avformat_new_stream(fmt_ctx, null);
    if (video_stream == null) {
        return error.FailedToCreateNewStream;
    }

    if (av.avcodec_parameters_from_context(video_stream.*.codecpar, enc_ctx) < 0) {
        return error.FailedToSetCodecParams;
    }

    // Create audio stream
    var audio_out_stream: ?*av.AVStream = null;
    if (audio_stream) |as| {
        audio_out_stream = av.avformat_new_stream(fmt_ctx, null);
        if (audio_out_stream == null) {
            return error.FailedToCreateAudioStream;
        }

        if (av.avcodec_parameters_copy(audio_out_stream.?.*.codecpar, as.*.codecpar) < 0) {
            return error.FailedToCopyAudioCodecParams;
        }
    }

    if (av.avio_open(&fmt_ctx.?.pb, output_path.ptr, av.AVIO_FLAG_WRITE) < 0) {
        return error.FailedToOpenOutputFile;
    }

    if (av.avformat_write_header(fmt_ctx, null) < 0) {
        return error.FailedToWriteHeader;
    }

    return .{ .ctx = fmt_ctx.?, .video_stream = video_stream, .audio_stream = audio_out_stream };
}

fn openAudioStream(fmt_ctx: *av.AVFormatContext) !AVStream {
    const index = av.av_find_best_stream(
        fmt_ctx,
        av.AVMEDIA_TYPE_AUDIO,
        -1,
        -1,
        null,
        0,
    );
    if (index < 0) {
        return error.AudioStreamNotFound;
    }

    return .{
        .stream = fmt_ctx.streams[@intCast(index)],
        .index = index,
    };
}

pub fn processVideo(allocator: std.mem.Allocator, args: core.CoreParams) !void {
    var input_ctx = try openInputVideo(args.input);
    defer av.avformat_close_input(@ptrCast(&input_ctx));

    const stream_info = try openVideoStream(input_ctx);
    var dec_ctx = try createDecoder(stream_info.stream);
    defer av.avcodec_free_context(@ptrCast(&dec_ctx));

    var enc_ctx = try createEncoder(dec_ctx, stream_info.stream, args);
    defer av.avcodec_free_context(@ptrCast(&enc_ctx));

    // Extract frame rate
    const input_frame_rate = @as(f64, @floatFromInt(stream_info.stream.*.r_frame_rate.num)) /
        @as(f64, @floatFromInt(stream_info.stream.*.r_frame_rate.den));
    const target_frame_rate = args.frame_rate orelse input_frame_rate;
    const frame_time_ns = @as(u64, @intFromFloat(1e9 / target_frame_rate));
    std.debug.print("Input FPS: {d}, Target FPS: {d}, FrameTime: {d}\n", .{ input_frame_rate, target_frame_rate, frame_time_ns });

    var audio_stream_info: ?AVStream = null;
    if (args.keep_audio) {
        audio_stream_info = openAudioStream(input_ctx) catch |err| blk: {
            if (err == error.AudioStreamNotFound) {
                std.debug.print("No audio stream found in input video. Continuing without audio.\n", .{});
                break :blk null;
            } else {
                return err;
            }
        };
    }

    var op: ?OutputContext = null;
    var t: term = undefined;
    var frames = std.ArrayList(core.Image).init(allocator);
    if (args.output) |output| {
        op = try createOutputCtx(output, enc_ctx, if (audio_stream_info) |asi| asi.stream else null);
        // Set up progress bar
    } else {
        t = try term.init(allocator, args.ascii_chars);
    }
    defer {
        if (op) |output| {
            _ = av.av_write_trailer(output.ctx);
            if ((output.ctx.oformat.*.flags & av.AVFMT_NOFILE) == 0) {
                _ = av.avio_closep(&output.ctx.pb);
            }
            av.avformat_free_context(output.ctx);
        } else {
            t.deinit();
        }
        for (frames.items) |f| {
            const img_len = f.height * f.width * f.channels;
            allocator.free(f.data[0..img_len]);
        }
        frames.deinit();
    }

    // Creates a FrameBuffer that holds enough frames for a 2 second buffer
    var frame_buf = FrameBuffer(core.Image).init(allocator, @as(usize, @intFromFloat(target_frame_rate * 2)));
    defer frame_buf.deinit();

    const producer_thread = try std.Thread.spawn(
        .{},
        producerTask,
        .{ allocator, &frame_buf, input_ctx, stream_info, audio_stream_info, dec_ctx, enc_ctx, op, t, args },
    );
    defer producer_thread.join();

    var processed_frames: usize = 0;
    const start_time = std.time.nanoTimestamp();
    var last_frame_time = std.time.nanoTimestamp();
    if (args.output_type != core.OutputType.Stdout) return;

    // Consume the frames and render if we are targeting stdout
    frame_buf.waitUntilReady();
    t.stats = .{
        .original_w = @intCast(dec_ctx.width),
        .original_h = @intCast(dec_ctx.height),
        .new_w = t.size.w,
        .new_h = t.size.h - 4,
    };
    try t.enableAsciiMode();
    defer t.disableAsciiMode() catch {};

    while (true) {
        const f = frame_buf.pop() orelse break;
        defer stb.stbi_image_free(f.data.ptr);

        const target_time: i128 = start_time + (@as(i128, processed_frames) * @as(i128, frame_time_ns));
        const curr_time = std.time.nanoTimestamp();
        const sleep_duration: i128 = target_time - curr_time;

        if (sleep_duration > 0) {
            std.time.sleep(@as(u64, @intCast(sleep_duration)));
        } else {
            // If we are lagging behind, we should probably log that we're not able to
            // match the target fps.
            // We will not sleep in this case.
        }

        const post_sleep_time = std.time.nanoTimestamp();
        const elapsed_seconds = @as(f32, @floatFromInt(post_sleep_time - start_time)) / 1e9;

        processed_frames += 1;
        t.stats.frame_count = processed_frames;
        t.stats.fps = @as(f32, @floatFromInt(processed_frames)) / elapsed_seconds;
        t.stats.frame_delay = @as(i64, @intCast(post_sleep_time - (start_time + ((processed_frames - 1) * frame_time_ns))));

        const adjusted_data = if (args.auto_adjust)
            try core.autoBrightnessContrast(allocator, f, 1.0)
        else
            f.data[0 .. f.width * f.height * f.channels];

        const adjusted_img = core.Image{
            .data = adjusted_data,
            .width = f.width,
            .height = f.height,
            .channels = f.channels,
        };
        defer if (args.auto_adjust) allocator.free(adjusted_data);

        const img_len = adjusted_img.height * adjusted_img.width * adjusted_img.channels;
        const params = term.RenderParams{
            .img = adjusted_img.data[0..img_len],
            .width = adjusted_img.width,
            .height = adjusted_img.height,
            .channels = adjusted_img.channels,
            .color = args.color,
            .invert = args.invert_color,
        };
        try t.renderAsciiArt(params);
        last_frame_time = curr_time;
    }

    for (frames.items) |f| {
        stb.stbi_image_free(f.data.ptr);
    }

    const avg_time = t.stats.total_time.? / @as(u128, t.stats.frame_count.?);
    t.stats.avg_frame_time = avg_time;
    std.debug.print("Average time for loop: {d}ms\n", .{t.stats.avg_frame_time.? / 1_000_000});
    std.debug.print("Total Time rendering: {d}ms\n", .{@divFloor((std.time.nanoTimestamp() - start_time), 1_000_000)});
}

fn producerTask(
    allocator: std.mem.Allocator,
    frame_buf: *FrameBuffer(core.Image),
    input_ctx: *av.AVFormatContext,
    stream_info: AVStream,
    audio_stream_info: ?AVStream,
    dec_ctx: *av.AVCodecContext,
    enc_ctx: *av.AVCodecContext,
    op: ?OutputContext,
    t: term,
    args: core.CoreParams,
) !void {
    // Get total frames
    var total_frames: usize = undefined;
    var progress: std.Progress.Node = undefined;
    var root_node: std.Progress.Node = undefined;
    var eta_node: std.Progress.Node = undefined;
    if (args.output_type == core.OutputType.Video) {
        total_frames = @intCast(getTotalFrames(input_ctx, stream_info));
        progress = std.Progress.start(.{});
        root_node = progress.start("Processing video", total_frames);
        eta_node = progress.start("(time elapsed (s)/time remaining(s))", 100);
    }

    var packet = av.av_packet_alloc();
    defer av.av_packet_free(&packet);

    var frame = av.av_frame_alloc();
    defer av.av_frame_free(&frame);

    var rgb_frame = av.av_frame_alloc();
    defer av.av_frame_free(&rgb_frame);

    const input_pix_fmt = dec_ctx.*.pix_fmt;
    std.debug.print("Input pixel format: {s}\n", .{av.av_get_pix_fmt_name(input_pix_fmt)});

    const output_pix_fmt = av.AV_PIX_FMT_RGB24;

    rgb_frame.*.format = output_pix_fmt;
    rgb_frame.*.width = @max(@divFloor(dec_ctx.*.width, args.block_size) * args.block_size, 1);
    rgb_frame.*.height = @max(@divFloor(dec_ctx.*.height, args.block_size) * args.block_size, 1);
    if (av.av_frame_get_buffer(rgb_frame, 0) < 0) {
        return error.FailedToAllocFrameBuf;
    }

    var yuv_frame = av.av_frame_alloc();
    defer av.av_frame_free(&yuv_frame);

    yuv_frame.*.format = av.AV_PIX_FMT_YUV420P;
    yuv_frame.*.width = enc_ctx.*.width;
    yuv_frame.*.height = enc_ctx.*.height;
    if (av.av_frame_get_buffer(yuv_frame, 0) < 0) {
        return error.FailedToAllocFrameBuf;
    }

    const sws_ctx = av.sws_getContext(
        dec_ctx.width,
        dec_ctx.height,
        input_pix_fmt,
        dec_ctx.width,
        dec_ctx.height,
        output_pix_fmt,
        av.SWS_BILINEAR,
        null,
        null,
        null,
    );
    defer av.sws_freeContext(sws_ctx);

    var term_ctx: ?*av.struct_SwsContext = undefined;
    var term_frame: *av.struct_AVFrame = undefined;
    if (op == null) {
        term_ctx = av.sws_getContext(
            dec_ctx.width,
            dec_ctx.height,
            output_pix_fmt,
            @intCast(t.size.w),
            @intCast(t.size.h),
            output_pix_fmt,
            av.SWS_BILINEAR,
            null,
            null,
            null,
        );
        term_frame = av.av_frame_alloc();
    }
    defer {
        if (op == null) {
            av.sws_freeContext(term_ctx.?);
            av.av_frame_free(&rgb_frame);
        }
    }

    // Set color space and range
    _ = av.sws_setColorspaceDetails(
        sws_ctx,
        av.sws_getCoefficients(av.SWS_CS_DEFAULT),
        0,
        av.sws_getCoefficients(av.SWS_CS_DEFAULT),
        0,
        0,
        (1 << 16) - 1,
        (1 << 16) - 1,
    );

    const out_sws_ctx = av.sws_getContext(
        rgb_frame.*.width,
        rgb_frame.*.height,
        @intCast(rgb_frame.*.format),
        yuv_frame.*.width,
        yuv_frame.*.height,
        @intCast(yuv_frame.*.format),
        av.SWS_BILINEAR,
        null,
        null,
        null,
    );
    defer av.sws_freeContext(out_sws_ctx);

    var frame_count: usize = 0;
    const start_time = std.time.milliTimestamp();
    var last_update_time = start_time;
    const update_interval: i64 = 1000; // Update every 1 second
    while (av.av_read_frame(input_ctx, packet) >= 0) {
        defer av.av_packet_unref(packet);

        if (packet.*.stream_index == stream_info.index) {
            if (av.avcodec_send_packet(dec_ctx, packet) < 0) {
                continue;
            }

            while (av.avcodec_receive_frame(dec_ctx, frame) >= 0) {
                _ = av.sws_scale(
                    sws_ctx,
                    &frame.*.data,
                    &frame.*.linesize,
                    0,
                    frame.*.height,
                    &rgb_frame.*.data,
                    &rgb_frame.*.linesize,
                );
                frame_count += 1;
                if (op) |output| {
                    try convertFrameToAscii(allocator, rgb_frame, args);
                    _ = av.sws_scale(
                        out_sws_ctx,
                        &rgb_frame.*.data,
                        &rgb_frame.*.linesize,
                        0,
                        rgb_frame.*.height,
                        &yuv_frame.*.data,
                        &yuv_frame.*.linesize,
                    );

                    yuv_frame.*.pts = frame.*.pts;

                    var enc_packet = av.av_packet_alloc();
                    defer av.av_packet_free(&enc_packet);

                    if (av.avcodec_send_frame(enc_ctx, yuv_frame) >= 0) {
                        while (av.avcodec_receive_packet(enc_ctx, enc_packet) >= 0) {
                            enc_packet.*.stream_index = 0;
                            enc_packet.*.pts = av.av_rescale_q(
                                enc_packet.*.pts,
                                enc_ctx.*.time_base,
                                output.video_stream.*.time_base,
                            );
                            enc_packet.*.dts = av.av_rescale_q(
                                enc_packet.*.dts,
                                enc_ctx.*.time_base,
                                output.video_stream.*.time_base,
                            );
                            enc_packet.*.duration = av.av_rescale_q(
                                enc_packet.*.duration,
                                enc_ctx.*.time_base,
                                output.video_stream.*.time_base,
                            );

                            _ = av.av_interleaved_write_frame(output.ctx, enc_packet);
                        }
                    }
                } else {
                    const frame_size = @as(usize, @intCast(rgb_frame.*.width)) * @as(usize, @intCast(rgb_frame.*.height)) * 3;
                    const frame_data = try allocator.alloc(u8, frame_size);
                    defer allocator.free(frame_data);
                    @memcpy(frame_data, rgb_frame.*.data[0][0..frame_size]);
                    const f = core.Image{
                        .data = frame_data,
                        .width = @intCast(rgb_frame.*.width),
                        .height = @intCast(rgb_frame.*.height),
                        .channels = 3,
                    };
                    const resized_img = try core.resizeImage(allocator, f, t.size.w, t.size.h - 4);
                    try frame_buf.push(resized_img);
                    if (frame_count == frame_buf.max_size) {
                        frame_buf.setReady();
                    }
                }
                if (args.output_type == core.OutputType.Video) {
                    root_node.completeOne();

                    const current_time = std.time.milliTimestamp();
                    if (current_time - last_update_time >= update_interval) {
                        const elapsed_time = @as(f64, @floatFromInt(current_time - start_time)) / 1000.0;
                        const frames_per_second = @as(f64, @floatFromInt(frame_count)) / elapsed_time;
                        const estimated_total_time = @as(f64, @floatFromInt(total_frames)) / frames_per_second;
                        const estimated_remaining_time = estimated_total_time - elapsed_time;

                        eta_node.setCompletedItems(@as(usize, (@intFromFloat(elapsed_time))));
                        eta_node.setEstimatedTotalItems(@intFromFloat(estimated_remaining_time));

                        last_update_time = current_time;
                    }
                }
            }
        } else if (args.keep_audio and audio_stream_info != null and packet.*.stream_index == audio_stream_info.?.index) {
            // Audio packet processing
            const output = op.?;
            packet.*.stream_index = output.audio_stream.?.index;
            packet.*.pts = av.av_rescale_q(packet.*.pts, audio_stream_info.?.stream.time_base, output.audio_stream.?.time_base);
            packet.*.dts = av.av_rescale_q(packet.*.dts, audio_stream_info.?.stream.time_base, output.audio_stream.?.time_base);
            packet.*.duration = av.av_rescale_q(packet.*.duration, audio_stream_info.?.stream.time_base, output.audio_stream.?.time_base);

            if (av.av_interleaved_write_frame(output.ctx, packet) < 0) {
                return error.FailedToWriteAudioPacket;
            }
        }
    }
}

fn convertFrameToAscii(allocator: std.mem.Allocator, frame: *av.AVFrame, args: core.CoreParams) !void {
    const img = core.Image{
        .data = frame.data[0][0 .. @as(usize, @intCast(frame.linesize[0])) * @as(usize, @intCast(frame.height))],
        .width = @intCast(frame.width),
        .height = @intCast(frame.height),
        .channels = 3,
    };

    const expected_size = img.width * img.height * img.channels;
    const adjusted_data = if (args.auto_adjust)
        try core.autoBrightnessContrast(allocator, img, 1.0)
    else
        try allocator.dupe(u8, @as([*]u8, @ptrCast(img.data))[0..expected_size]);

    const adjusted_img = core.Image{
        .data = adjusted_data,
        .width = img.width,
        .height = img.height,
        .channels = img.channels,
    };
    defer if (args.auto_adjust) allocator.free(adjusted_data);

    const edge_result = try core.detectEdges(allocator, adjusted_img, args.detect_edges, args.sigma1, args.sigma2);

    const ascii_img = try core.generateAsciiArt(allocator, adjusted_img, edge_result, args);

    // Copy ascii art back to frame
    const out_w = (adjusted_img.width / args.block_size) * args.block_size;
    const out_h = (adjusted_img.height / args.block_size) * args.block_size;
    const frame_linesize = @as(usize, @intCast(frame.linesize[0]));

    for (0..out_h) |y| {
        const src_start = y * out_w * 3;
        const dst_start = y * frame_linesize;
        const row_size = @min(out_w * 3, frame_linesize);
        @memcpy(frame.data[0][dst_start..][0..row_size], ascii_img[src_start..][0..row_size]);
    }
}

fn getTotalFrames(fmt_ctx: *av.AVFormatContext, stream_info: AVStream) i64 {
    if (stream_info.stream.nb_frames > 0) {
        return stream_info.stream.nb_frames;
    }

    var total_frames: i64 = 0;
    var pkt: av.AVPacket = undefined;
    while (av.av_read_frame(fmt_ctx, &pkt) >= 0) {
        defer av.av_packet_unref(&pkt);
        if (pkt.stream_index == stream_info.index) {
            total_frames += 1;
        }
    }

    // Reset the file position indicator
    _ = av.avio_seek(fmt_ctx.*.pb, 0, av.SEEK_SET);
    _ = av.avformat_seek_file(
        fmt_ctx,
        stream_info.index,
        std.math.minInt(i64),
        0,
        std.math.maxInt(i64),
        0,
    );

    return total_frames;
}



================================================
File: vendor/av.zig
================================================
pub usingnamespace @cImport({
    @cInclude("libavformat/avformat.h");
    @cInclude("libavcodec/avcodec.h");
    @cInclude("libavutil/avutil.h");
    @cInclude("libavutil/imgutils.h");
    @cInclude("libavutil/opt.h");
    @cInclude("libswscale/swscale.h");
    @cInclude("libswresample/swresample.h");
    @cInclude("libavutil/channel_layout.h");
    @cInclude("libavutil/samplefmt.h");
});



================================================
File: vendor/stb.c
================================================
#define STB_IMAGE_IMPLEMENTATION
#define STB_IMAGE_WRITE_IMPLEMENTATION
#define STB_IMAGE_RESIZE_IMPLEMENTATION
#include "stb_image.h"
#include "stb_image_write.h"
#include "stb_image_resize2.h"



================================================
File: vendor/stb.zig
================================================
pub usingnamespace @cImport({
    @cInclude("stb_image.h");
    @cInclude("stb_image_write.h");
    @cInclude("stb_image_resize2.h");
});



================================================
File: .github/workflows/bump.yml
================================================
on:
  workflow_dispatch:
  release:
    types: [published]

jobs:
  bump:
    runs-on: ubuntu-latest
    steps:
      - name: Set up Homebrew
        uses: Homebrew/actions/setup-homebrew@master

      - name: Update Homebrew formula
        uses: dawidd6/action-homebrew-bump-formula@v3
        with:
          token: ${{secrets.BREW_ACTION_TOKEN}}
          no_fork: true
          tap: seatedro/asciigen
          formula: asciigen



================================================
File: .github/workflows/release.yml
================================================
name: Build and Release

on:
  push:
    tags:
      - "v*"

jobs:
  build:
    name: Build ${{ matrix.target }}
    runs-on: ${{ matrix.os }}

    strategy:
      matrix:
        include:
          - os: macos-latest
            target: aarch64-macos
          - os: macos-13
            target: x86_64-macos
          - os: ubuntu-latest
            target: x86_64-linux
          - os: ubuntu-24.04
            target: aarch64-linux
          - os: windows-latest
            target: x86_64-windows

    steps:
      - uses: actions/checkout@v4

      - name: Setup Zig
        uses: mlugg/setup-zig@v1
        with:
          version: 0.14.0

      - name: Setup FFmpeg (macOS)
        if: runner.os == 'macOS'
        run: brew install ffmpeg pkgconf coreutils

      - name: Setup FFmpeg (Linux)
        if: runner.os == 'Linux'
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg libavcodec-dev libavformat-dev libavutil-dev libswscale-dev libswresample-dev pkg-config

      - name: Setup FFmpeg (Windows)
        if: runner.os == 'Windows'
        run: |
          choco install -y ffmpeg-shared
          set INCLUDE=%INCLUDE%;"C:\ProgramData\chocolatey\lib\ffmpeg-shared\tools\ffmpeg-7.1-full_build-shared\include"
          set LIB=%LIB%;"C:\ProgramData\chocolatey\lib\ffmpeg-shared\tools\ffmpeg-7.1-full_build-shared\lib"

      - name: Build
        run: |
          zig build -Doptimize=ReleaseFast -Dstrip=true
          tar czf glyph-${{ matrix.target }}.tar.gz -C zig-out/bin .
          sha256sum glyph-${{ matrix.target }}.tar.gz > glyph-${{ matrix.target }}.tar.gz.sha256

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts-${{ matrix.target }}
          path: glyph-*

  release:
    needs: build
    runs-on: ubuntu-latest
    permissions: "write-all"
    steps:
      - uses: actions/download-artifact@v4
        with:
          pattern: build-artifacts-*
          path: artifacts
          merge-multiple: true

      - name: Release
        uses: softprops/action-gh-release@v2
        with:
          files: artifacts/*
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}



================================================
File: .github/workflows/test.yml
================================================
name: Test

on:
  pull_request:
    branches:
      - main

jobs:
  build-and-test:
    name: Build and Test on ${{ matrix.os }} (${{ matrix.arch }})
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        include:
          # arm
          - os: macos-latest
            arch: aarch64
          - os: macos-13
            arch: x86_64
          - os: ubuntu-24.04
            arch: aarch64
          # x86
          - os: ubuntu-latest
            arch: x86_64
          - os: windows-latest
            arch: x86_64

    steps:
    - uses: actions/checkout@v4

    - name: Set up Zig
      uses: mlugg/setup-zig@v1
      with:
        version: 0.14.0


    - name: Setup FFmpeg (macos)
      if: runner.os == 'macOS'
      run: brew install ffmpeg pkgconf coreutils

    - name: Setup FFmpeg (Linux)
      if: runner.os == 'Linux'
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg libavcodec-dev libavformat-dev libavutil-dev libswscale-dev libswresample-dev pkg-config

    - name: Setup FFmpeg (Windows)
      if: runner.os == 'Windows'
      run: |
        choco install -y ffmpeg-shared
        set INCLUDE=%INCLUDE%;"C:\ProgramData\chocolatey\lib\ffmpeg-shared\tools\ffmpeg-7.1-full_build-shared\include"
        set LIB=%LIB%;"C:\ProgramData\chocolatey\lib\ffmpeg-shared\tools\ffmpeg-7.1-full_build-shared\lib"

    - name: Test
      run: |
        zig build --release=fast test

    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: test_output-${{ matrix.os }}-${{ matrix.arch }}
        path: test_output/


